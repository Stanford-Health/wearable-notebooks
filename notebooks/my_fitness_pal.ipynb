{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPbhfm8BemdN"
   },
   "source": [
    "# MyFitnessPal: Guide to data extraction and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXqYLOxNeoX_"
   },
   "source": [
    "<img src=\"https://i.imgur.com/4g4i8g8.png\" height=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0QR03kueqpK"
   },
   "source": [
    "A picture of the MyFitnessPal Mobile Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZZHXApgesVP"
   },
   "source": [
    "Do you know that DIET stands for Did I Eat That? <br> <br>\n",
    "Jokes aside, in this notebook we will be doing just that. We will connect to the Cronometer API to analyze the participants nutritional and exercise habits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBNVIh27et3L"
   },
   "source": [
    "MyFitnessPal is regarded as a personal diary for logging nutrition and exercise. It lets you track your meals and workouts and provides you with required nutrition figures to attain your desired body measurements.\n",
    "\n",
    "MyFitnessPal follows a freemium model offering a digital service accessible through its mobile applications (iOS and Android). Users also have an option to upgrade and unlock more advanced features like Custom Calorie Goals, In-depth meal Analysis, Workout Routines, etc for a monthly fee of $9.99.\n",
    "\n",
    "We've been using the MyFitnessPlan application for the past few weeks and we will show you how to extract its data, visualize your meals and compute correlations between multiple metrics of the data. Wearipedia can easily extract from MyFitnessPal servers for our use case.\n",
    "\n",
    "\n",
    "For this notebook we will be focusing on metrics of the participant's activities like calories, micronutrients, macronutrients, workouts, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnb9q2Qiev_f"
   },
   "source": [
    "We will be able to extract the following parameters:\n",
    "\n",
    "Parameter Name  | Sampling Frequency \n",
    "-------------------|-----------------\n",
    "Calorie Intake |  Per Food Item \n",
    "Carbohydrates |  Per Food Item \n",
    "Fat |  Per Food Item\n",
    "Protein |  Per Food Item\n",
    "Sodium |  Per Food Item\n",
    "Sugar |  Per Food Item \n",
    "Vitamin A |  Per Food Item \n",
    "Vitamin C |  Per Food Item \n",
    "Iron |  Per Food Item \n",
    "Calcium |  Per Food Item \n",
    "Fibre |  Per Food Item \n",
    "Calories Burned |  Per Activity \n",
    "Sets/Reps |  Per Exercise\n",
    "Weights |  Per Exercise\n",
    "Weight |  Depending upon User's inputs\n",
    "Height |  Depending upon User's inputs\n",
    "Neck |  Depending upon User's inputs\n",
    "Waist |  Depending upon User's inputs\n",
    "Hips |  Depending upon User's inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calories and nutrients are subsets of goals, dailySummary, lunch, breakfast and dinner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAzDNzYjeyY4"
   },
   "source": [
    "In this guide, we sequentially cover the following **five** topics to extract data from Cronometer servers:\n",
    "\n",
    "1. **Setup**<br>\n",
    "2. **Authentication and Authorization**<br>\n",
    "   - Requires cookies from your browser to login.<br>\n",
    "3. **Data Extraction**<br>\n",
    "  - We get data via wearipedia in a couple lines of code<br>\n",
    "4. **Data Exporting**\n",
    "    - We export all of this data to file formats compatible by R, Excel, and MatLab.\n",
    "5. **Adherence**\n",
    "    - We simulate non-adherence by dynamically removing datapoints from our simulated data.\n",
    "6. **Visualization**\n",
    "    - We create a simple plot to visualize our data.\n",
    "7. **Advanced Visualization**\n",
    "    - 7.1 Visualizing participant's Weekly Calorie Intake! <br>\n",
    "    - 7.2 Visualizing participant's Weekly Workout Repetitions! <br>\n",
    "    - 7.3 Visualizing Participant's Weekly Carbohydrate Intake! <br>\n",
    "8. **Statistical Data Analysis** <br>\n",
    "  - 8.1  Checking Protein Intake! <br>\n",
    "9. **Outlier Detection and Data Cleaning** <br>\n",
    "  - 9.1 Highlighting Outliers!\n",
    "\n",
    "Disclaimer: this notebook is purely for educational purposes. All of the data currently stored in this notebook is purely *synthetic*, meaning randomly generated according to rules we created. Despite this, the end-to-end data extraction pipeline has been tested on our own data, meaning that if you enter your own cookies on your own Colab instance, you can visualize your own *real* data. That being said, we were unable to thoroughly test the timezone functionality, though, since we only have one account, so beware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NilGl0FGe0gr"
   },
   "source": [
    "# 1. Setup\n",
    "\n",
    "## Participant Setup\n",
    "\n",
    "Dear Participant,\n",
    "\n",
    "Once you download the MyFitnessPal app, please set it up by following these resources:\n",
    "- Written guide: https://blog.myfitnesspal.com/essential-guide-to-food-logging\n",
    "- Video guide: https://www.youtube.com/watch?v=fu9RKqlmD1Q&ab_channel=MyFitnessPalApp\n",
    "\n",
    "Make sure that your phone is logged to the MyFitnessPal app using the MyFitnessPal login credentials (email and password) given to you by the data receiver.\n",
    "\n",
    "Best,\n",
    "\n",
    "Wearipedia\n",
    "\n",
    "## Data Receiver Setup\n",
    "\n",
    "Please follow the below steps:\n",
    "\n",
    "1. Create an email address for the participant, for example `foo@email.com`.\n",
    "2. Create a MyFitnessPal account with the email `foo@email.com` and some random password.\n",
    "3. Keep `foo@email.com` and password stored somewhere safe.\n",
    "4. Distribute the device to the participant and instruct them to follow the participant setup letter above.\n",
    "5. Install the `wearipedia` Python package to easily extract data from this device via the Cronometer API.\n",
    "6. Make sure that your MyFitnessPal account is logged into your browser inorder to correctly extract the cookies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTwt3g0SeiiN",
    "outputId": "45447683-3871-4b0c-c5ba-f616fcd6542c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (3.0.10)\n",
      "Requirement already satisfied: et_xmlfile in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "Found existing installation: seaborn 0.11.1\n",
      "Uninstalling seaborn-0.11.1:\n",
      "  Successfully uninstalled seaborn-0.11.1\n",
      "Collecting seaborn==0.11.1\n",
      "  Using cached seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from seaborn==0.11.1) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from seaborn==0.11.1) (1.9.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from seaborn==0.11.1) (3.6.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from seaborn==0.11.1) (1.21.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn==0.11.1) (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn==0.11.1) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn==0.11.1) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn==0.11.1) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn==0.11.1) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn==0.11.1) (8.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn==0.11.1) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.2->seaborn==0.11.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.23->seaborn==0.11.1) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/saarth/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.1) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wearipedia\n",
    "!pip install openpyxl\n",
    "!pip uninstall -y seaborn\n",
    "!pip install seaborn==0.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wearipedia\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import http.cookiejar as cookiejar\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta, date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCzIx1k1e6Qh"
   },
   "source": [
    "# 2. Authentication and Authorization\n",
    "\n",
    "To obtain access to data, authorization is required. Unfortunately, for MyFitnessPal, just using email and password is not sufficient to authorize data extraction from their API. We will have to extract the cookies stored on your local machine inorder to authenticate agaist the MyFitnessPal API. \n",
    "\n",
    "Note: If you are running this on your local machine (where MyFitnessPal is logged in), you most likely would not have to seperately extract cookies to do this. However to get MyFitnessPal working for Google colab we will have to go through this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5j-0XomrDUSW"
   },
   "source": [
    "Step 1: Run the following python script on your local machine. \n",
    "\n",
    "\n",
    "```\n",
    "import browsercookie\n",
    "import json\n",
    "import http.cookiejar as cookiejar\n",
    "\n",
    "# Extracts all the user cookies from the browser and saves them in a file\n",
    "def download_cookies():\n",
    "\n",
    "    cookies = browsercookie.load()\n",
    "    cookiefiles = []\n",
    "\n",
    "    # Add the cookies to the CookieJar object\n",
    "    for cookie in cookies:\n",
    "        cookie_dict = cookie.__dict__\n",
    "        cookie_dict['rest'] = cookie_dict['_rest']\n",
    "        del cookie_dict['_rest']\n",
    "        cookiefiles.append(cookie_dict)\n",
    "\n",
    "    # Save the cookies to the JSON file\n",
    "    with open('cookies.json', 'w') as f:\n",
    "        json.dump(cookiefiles, f)\n",
    "\n",
    "# Calling the function\n",
    "download_cookies()\n",
    "```\n",
    "\n",
    "This should create a file called <b><i>cookies.json</b></i> within the same directory.<br>\n",
    "<img src='https://i.imgur.com/tNTNFKv.png'>\n",
    "\n",
    "\n",
    "Step 2: Upload the exctracted json file in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "INRAosqYe2yZ",
    "outputId": "62c591a3-0a9b-4d3d-f19e-779c098909c7"
   },
   "outputs": [],
   "source": [
    "# Set whether you're running this locally, or in colab. If local, you can set the filepath below.\n",
    "running_in_colab = True #@param {type:\"boolean\"}\n",
    "\n",
    "if running_in_colab:  \n",
    "    from google.colab import files\n",
    "    cookies = files.upload()\n",
    "    with open(list(cookies.keys())[0], 'r') as f:\n",
    "        data = json.load(f)\n",
    "else:\n",
    "    # Set the filepath here\n",
    "    cookie_filepath = \"\" #@param {type:\"string\"}\n",
    "    with open(cookie_filepath) as f:\n",
    "       data = json.load(f)\n",
    "\n",
    "jar2 = cookiejar.CookieJar()\n",
    "for cookie in data:\n",
    "  jar2.set_cookie(cookiejar.Cookie(**cookie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWVelqzHe-L2"
   },
   "source": [
    "# 3. Data Extraction\n",
    "\n",
    "Data can be extracted via [wearipedia](https://github.com/Stanford-Health/wearipedia/), our open-source Python package that unifies dozens of complex wearable device APIs into one simple, common interface.\n",
    "\n",
    "First, we'll set a date range and then extract all of the data within that date range. You can select whether you would like synthetic data or not with the checkbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imNqkTSpe8GP"
   },
   "outputs": [],
   "source": [
    "#@title Enter start and end dates (in the format yyyy-mm-dd)\n",
    "\n",
    "#set start and end dates - this will give you all the data from 2000-01-01 (January 1st, 2000) to 2100-02-03 (February 3rd, 2100), for example\n",
    "start_date='2022-03-01' #@param {type:\"string\"}\n",
    "end_date='2022-06-17' #@param {type:\"string\"}\n",
    "synthetic = True #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-pWdzEzfAbN"
   },
   "outputs": [],
   "source": [
    "device = wearipedia.get_device(\"myfitnesspal/myfitnesspal\")\n",
    "\n",
    "if not synthetic:\n",
    "    # Cookie jar will be passed as a parameter. If nothing is passed, our \n",
    "    # authenticate function will try to use locally stored cookies.\n",
    "    device.authenticate({'cookies':jar2})\n",
    "\n",
    "params = {\"start_date\": start_date, \"end_date\": end_date}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nykg-QdQLia2"
   },
   "source": [
    "After authentication, we can finally load our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLqAtaOALOfA"
   },
   "outputs": [],
   "source": [
    "goals = device.get_data(\"goals\", params=params)\n",
    "daily_summary = device.get_data('daily_summary',params=params)\n",
    "exercises_cardio = device.get_data('exercises_cardio',params=params)\n",
    "exercises_strength = device.get_data('exercises_strength',params=params)\n",
    "lunch = device.get_data('lunch',params=params)\n",
    "breakfast = device.get_data('breakfast',params=params)\n",
    "dinner = device.get_data('dinner',params=params)\n",
    "snacks = device.get_data('snacks',params=params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kA0mnAEtfjGw"
   },
   "source": [
    "# 4. Data Exporting\n",
    "\n",
    "In this section, we export all of this data to formats compatible with popular scientific computing software (R, Excel, Google Sheets, Matlab). Specifically, we will first export to JSON, which can be read by R and Matlab. Then, we will export to CSV, which can be consumed by Excel, Google Sheets, and every other popular programming language.\n",
    "\n",
    "## Exporting to JSON (R, Matlab, etc.)\n",
    "\n",
    "Exporting to JSON is fairly simple. We export each datatype separately and also export a complete version that includes all simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vxorcs9OUcV"
   },
   "outputs": [],
   "source": [
    "# This function will cleanup the timestamp objects and convert them to text\n",
    "# as timestamp objects are not JSON Serializable\n",
    "def datacleanup(data):\n",
    "  res = []\n",
    "  for d in data:\n",
    "    if 'date' in d:\n",
    "      d['date'] = str(d['date'])\n",
    "    if type(d)==list:\n",
    "      if 'day' in d[0]:\n",
    "        d[0]['day'] = str(d[0]['day'])\n",
    "      if 'date' in d[0]:\n",
    "        d[0]['date'] = str(d[0]['date'])\n",
    "    res.append(d)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwl4BMTrfEdG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "json.dump(datacleanup(goals), open(\"goals.json\", \"w\"))\n",
    "json.dump(datacleanup(daily_summary), open(\"daily_summary.json\", \"w\"))\n",
    "json.dump(datacleanup(exercises_cardio), open(\"exercises_cardio.json\", \"w\"))\n",
    "json.dump(datacleanup(exercises_strength), open(\"exercises_strength.json\", \"w\"))\n",
    "json.dump(datacleanup(lunch), open(\"lunch.json\", \"w\"))\n",
    "json.dump(datacleanup(breakfast), open(\"breakfast.json\", \"w\"))\n",
    "json.dump(datacleanup(dinner), open(\"dinner.json\", \"w\"))\n",
    "json.dump(datacleanup(snacks), open(\"snacks.json\", \"w\"))\n",
    "\n",
    "complete = {\n",
    "    \"goals\": goals,\n",
    "    \"daily_summary\": daily_summary,\n",
    "    \"exercises_cardio\": exercises_cardio,\n",
    "    \"exercises_strength\": exercises_strength,\n",
    "    \"lunch\": lunch,\n",
    "    \"breakfast\": breakfast,\n",
    "    \"dinner\": dinner,\n",
    "    \"snacks\": snacks,\n",
    "}\n",
    "\n",
    "json.dump(complete, open(\"complete.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHcdzBcMf6SU"
   },
   "source": [
    "Feel free to open the file viewer (see left pane) to look at the outputs!\n",
    "\n",
    "## Exporting to CSV and XLSX (Excel, Google Sheets, R, Matlab, etc.)\n",
    "\n",
    "Exporting to CSV/XLSX requires a bit more processing, since they enforce a pretty restrictive schema.\n",
    "\n",
    "We will thus export steps, heart rates, and breath rates all as separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWuVEFnT0Yub"
   },
   "outputs": [],
   "source": [
    "dailySummary_df = pd.DataFrame.from_dict(daily_summary)\n",
    "dailySummary_df.to_csv('dailySummary.csv')\n",
    "dailySummary_df.to_excel('dailySummary.xlsx')\n",
    "\n",
    "goals_df = pd.DataFrame.from_dict(goals)\n",
    "\n",
    "goals_df.to_csv('goals.csv', index=False)\n",
    "goals_df.to_excel('goals.xlsx', index=False)\n",
    "\n",
    "exercises_cardio_df = pd.DataFrame()\n",
    "\n",
    "for e in exercises_cardio:\n",
    "    for exercise in e[1:]:\n",
    "        data_dict = {\n",
    "            'day':e[0]['day'],\n",
    "            'name':exercise['name'],\n",
    "            'nutrition_information':[exercise['nutrition_information']]\n",
    "        }\n",
    "        \n",
    "        data_dict_df = pd.DataFrame.from_dict(data_dict)\n",
    "        exercises_cardio_df = pd.concat([exercises_cardio_df,data_dict_df], ignore_index=True)\n",
    "\n",
    "\n",
    "exercises_cardio_df.to_csv('exercises_cardio.csv', index=False)\n",
    "exercises_cardio_df.to_excel('exercises_cardio.xlsx', index=False)\n",
    "\n",
    "exercises_strength_df = pd.DataFrame()\n",
    "\n",
    "for e in exercises_strength:\n",
    "    for exercise in e[1:]:\n",
    "        data_dict = {\n",
    "            'day':e[0]['date'],\n",
    "            'name':exercise['name'],\n",
    "            'nutrition_information':[exercise['nutrition_information']]\n",
    "        }\n",
    "        data_dict_df = pd.DataFrame.from_dict(data_dict)\n",
    "        exercises_strength_df = pd.concat([exercises_strength_df,data_dict_df], ignore_index=True)\n",
    "\n",
    "exercises_strength_df.to_csv('exercises_strength.csv', index=False)\n",
    "exercises_strength_df.to_excel('exercises_strength.xlsx', index=False)\n",
    "\n",
    "lunch_df = pd.DataFrame()\n",
    "\n",
    "lunch_df = lunch_df.assign(day=[e[0]['day'] for e in \n",
    "lunch])\n",
    "lunch_df = lunch_df.assign(name=[e[1]['name'] for e in \n",
    "lunch])\n",
    "lunch_df = lunch_df.assign(nutrition_information=\n",
    "[l[1]['nutrition_information'] for l in lunch])\n",
    "lunch_df = lunch_df.assign(totals=\n",
    "[l[1]['totals'] for l in lunch])\n",
    "\n",
    "lunch_df.to_csv('lunch.csv', index=False)\n",
    "lunch_df.to_excel('lunch.xlsx', index=False)\n",
    "\n",
    "dinner_df = pd.DataFrame()\n",
    "\n",
    "dinner_df = dinner_df.assign(day=[e[0]['day'] for e in \n",
    "dinner])\n",
    "dinner_df = dinner_df.assign(name=[l[1]['name'] for l in \n",
    "dinner])\n",
    "dinner_df = dinner_df.assign(nutrition_information=\n",
    "[l[1]['nutrition_information'] for l in dinner])\n",
    "dinner_df = dinner_df.assign(totals=\n",
    "[l[1]['totals'] for l in dinner])\n",
    "\n",
    "dinner_df.to_csv('dinner.csv', index=False)\n",
    "dinner_df.to_excel('dinner.xlsx', index=False)\n",
    "\n",
    "breakfast_df = pd.DataFrame()\n",
    "\n",
    "breakfast_df = breakfast_df.assign(day=[e[0]['day'] for e in \n",
    "breakfast])\n",
    "breakfast_df = breakfast_df.assign(name=[l[1]['name'] for l in \n",
    "breakfast])\n",
    "breakfast_df = breakfast_df.assign(nutrition_information=\n",
    "[l[1]['nutrition_information'] for l in breakfast])\n",
    "breakfast_df = breakfast_df.assign(totals=\n",
    "[l[1]['totals'] for l in breakfast])\n",
    "\n",
    "breakfast_df.to_csv('breakfast.csv', index=False)\n",
    "breakfast_df.to_excel('breakfast.xlsx', index=False)\n",
    "\n",
    "\n",
    "snacks_df = pd.DataFrame()\n",
    "\n",
    "snacks_df = snacks_df.assign(day=[e[0]['day'] for e in \n",
    "snacks])\n",
    "snacks_df = snacks_df.assign(name=[l[1]['name'] for l in \n",
    "snacks])\n",
    "snacks_df = snacks_df.assign(nutrition_information=\n",
    "[l[1]['nutrition_information'] for l in snacks])\n",
    "snacks_df = snacks_df.assign(totals=\n",
    "[l[1]['totals'] for l in snacks])\n",
    "\n",
    "snacks_df.to_csv('snacks.csv', index=False)\n",
    "snacks_df.to_excel('snacks.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNRvGqso8Njy"
   },
   "source": [
    "Again, feel free to look at the output files and download them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1N2qX298Q52"
   },
   "source": [
    "# 5. Adherence\n",
    "\n",
    "The device simulator already automatically randomly deletes small chunks of the day. In this section, we will simulate non-adherence over longer periods of time from the participant (day-level and week-level).\n",
    "\n",
    "Then, we will detect this non-adherence and give a Pandas DataFrame that concisely describes when the participant has had their device on and off throughout the entirety of the time period, allowing you to calculate how long they've had it on/off etc.\n",
    "\n",
    "We will first delete a certain % of blocks either at the day level or week level, with user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7ezn7YL5z60"
   },
   "outputs": [],
   "source": [
    "#@title Non-adherence simulation\n",
    "block_level = \"day\" #@param [\"day\", \"week\"]\n",
    "adherence_percent = 0.89 #@param {type:\"slider\", min:0, max:1, step:0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZIuef9Rq8Zfr"
   },
   "outputs": [],
   "source": [
    "if block_level == \"day\":\n",
    "    block_length = 1\n",
    "elif block_level == \"week\":\n",
    "    block_length = 7\n",
    "\n",
    "\n",
    "\n",
    "# This function will randomly remove datapoints from the \n",
    "# data we have recieved from Cronometer based on the\n",
    "# adherence_percent\n",
    "\n",
    "def AdherenceSimulator(data):\n",
    "\n",
    "  num_blocks = len(data) // block_length\n",
    "  num_blocks_to_keep = int(adherence_percent * num_blocks)\n",
    "  idxes = np.random.choice(np.arange(num_blocks), replace=False, \n",
    "  size=num_blocks_to_keep)\n",
    "\n",
    "  adhered_data = []\n",
    "\n",
    "  for i in range(len(data)):\n",
    "      if i in idxes:\n",
    "          start = i * block_length\n",
    "          end = (i + 1) * block_length\n",
    "          for j in range(i,i+1):\n",
    "            adhered_data.append(data[j])\n",
    "  \n",
    "  return adhered_data\n",
    "\n",
    "\n",
    "# Adding adherence for daily summary\n",
    "\n",
    "dailySummary = AdherenceSimulator(daily_summary)\n",
    "\n",
    "# Adding adherence for strength exercises\n",
    "\n",
    "exercises_strength = AdherenceSimulator(exercises_strength)\n",
    "\n",
    "# Adding adherence for cardio exercises\n",
    "\n",
    "exercises_cardio = AdherenceSimulator(exercises_cardio)\n",
    "\n",
    "# Adding adherence for goals\n",
    "\n",
    "goals = AdherenceSimulator(goals)\n",
    "\n",
    "# Adding adherence for lunch\n",
    "\n",
    "lunch = AdherenceSimulator(lunch)\n",
    "\n",
    "# Adding adherence for dinner\n",
    "\n",
    "dinner = AdherenceSimulator(dinner)\n",
    "\n",
    "# Adding adherence for breakfast\n",
    "\n",
    "breakfast = AdherenceSimulator(breakfast)\n",
    "\n",
    "# Adding adherence for snacks\n",
    "\n",
    "snacks = AdherenceSimulator(snacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7_OF1Zj53w"
   },
   "source": [
    "And now we have significantly fewer datapoints! This will give us a more realistic situation, where participants may take off their device for days or weeks at a time.\n",
    "\n",
    "Now let's detect non-adherence. We will return a Pandas DataFrame sampled at every day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gf5Jp8HXjm0e"
   },
   "outputs": [],
   "source": [
    "dailySummary_df = pd.DataFrame.from_dict(daily_summary)\n",
    "\n",
    "goals_df = pd.DataFrame.from_dict(goals)\n",
    "\n",
    "exercises_cardio_df = pd.DataFrame()\n",
    "exercises_cardio_df = exercises_cardio_df.assign(day=[e[0]['day'] for e in \n",
    "exercises_cardio])\n",
    "exercises_cardio_df = exercises_cardio_df.assign(name=[e[1]['name'] for e in \n",
    "exercises_cardio])\n",
    "exercises_cardio_df = exercises_cardio_df.assign(nutrition_information=\n",
    "[e[1]['nutrition_information'] for e in exercises_cardio])\n",
    "\n",
    "exercises_strength_df = pd.DataFrame()\n",
    "exercises_strength_df = exercises_strength_df.assign(day=[e[0]['date'] for e in \n",
    "exercises_strength])\n",
    "exercises_strength_df = exercises_strength_df.assign(name=[e[1]['name'] for e in \n",
    "exercises_strength])\n",
    "exercises_strength_df = exercises_strength_df.assign(nutrition_information=\n",
    "[e[1]['nutrition_information'] for e in exercises_strength])\n",
    "\n",
    "lunch_df = pd.DataFrame()\n",
    "lunch_df = lunch_df.assign(day=[e[0]['day'] for e in \n",
    "lunch])\n",
    "lunch_df = lunch_df.assign(name=[e[1]['name'] for e in \n",
    "lunch])\n",
    "lunch_df = lunch_df.assign(nutrition_information=\n",
    "[l[1]['nutrition_information'] for l in lunch])\n",
    "lunch_df = lunch_df.assign(totals=\n",
    "[l[1]['totals'] for l in lunch])\n",
    "\n",
    "dinner_df = pd.DataFrame()\n",
    "dinner_df = dinner_df.assign(day=[e[0]['day'] for e in \n",
    "dinner])\n",
    "dinner_df = dinner_df.assign(name=[l[1]['name'] for l in \n",
    "dinner])\n",
    "dinner_df = dinner_df.assign(nutrition_information=\n",
    "[l[1]['nutrition_information'] for l in dinner])\n",
    "dinner_df = dinner_df.assign(totals=\n",
    "[l[1]['totals'] for l in dinner])\n",
    "\n",
    "breakfast_df = pd.DataFrame()\n",
    "breakfast_df = breakfast_df.assign(day=[e[0]['day'] for e in \n",
    "breakfast])\n",
    "breakfast_df = breakfast_df.assign(name=[l[1]['name'] for l in \n",
    "breakfast])\n",
    "breakfast_df = breakfast_df.assign(nutrition_information=\n",
    "[l[1]['nutrition_information'] for l in breakfast])\n",
    "breakfast_df = breakfast_df.assign(totals=\n",
    "[l[1]['totals'] for l in breakfast])\n",
    "\n",
    "snacks_df = pd.DataFrame()\n",
    "snacks_df = snacks_df.assign(day=[e[0]['day'] for e in \n",
    "snacks])\n",
    "snacks_df = snacks_df.assign(name=[l[1]['name'] for l in \n",
    "snacks])\n",
    "snacks_df = snacks_df.assign(nutrition_information=\n",
    "[l[1]['nutrition_information'] for l in snacks])\n",
    "snacks_df = snacks_df.assign(totals=\n",
    "[l[1]['totals'] for l in snacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvsDKGzxnTAN"
   },
   "source": [
    "We can plot this out, and we get adherence at one-day frequency throughout the entirety of the data collection period. For this chart we will plot Calories consumed during breakfast over the time period from the breakfast dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "awU2gtJXmcnP",
    "outputId": "df03d1e6-16fd-48c1-d305-ee8e5ebef78c"
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range(start_date,end_date)\n",
    "\n",
    "calories = []\n",
    "\n",
    "for d in dates:\n",
    "  res = lunch_df[lunch_df.day == datetime.strftime(d,\n",
    "  '%Y-%m-%d')+' 00:00:00']['nutrition_information']\n",
    "  if len(res) == 0:\n",
    "    calories.append(None)\n",
    "  else:\n",
    "    calories.append(res.iloc[0]['calories'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates, calories)\n",
    "plt.ylabel('Calories Consumed')\n",
    "plt.xlabel('Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this, let's calculate the distribution of days where then calorie consumption was surprisingly low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the threshold for \"surprisingly low\" calories\n",
    "surprisingly_low_threshold = 100.0\n",
    "\n",
    "# Count the days with surprisingly low calories\n",
    "surprisingly_low_days = sum(1 for c in calories if c is not None and c < surprisingly_low_threshold)\n",
    "\n",
    "# Count the days with calories above the threshold\n",
    "non_surprisingly_low_days = len(calories) - surprisingly_low_days\n",
    "\n",
    "# Data for the bar plot\n",
    "categories = ['Surprisingly Low (<100)', 'Not Surprisingly Low (>100)']\n",
    "values = [surprisingly_low_days, non_surprisingly_low_days]\n",
    "\n",
    "# Set the Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create the bar plot using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=categories, y=values, palette=['green', 'blue'])\n",
    "plt.title('Distribution of Days with Surprisingly Low Calories Consumed')\n",
    "plt.ylabel('Number of Days')\n",
    "plt.xlabel('Calorie Consumption')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOsrr4s0re5Y"
   },
   "source": [
    "# 6. Visualization\n",
    "\n",
    "We've extracted lots of data, but what does it look like?\n",
    "\n",
    "In this section, we will be visualizing our three kinds of data in a simple, customizable plot! This plot is intended to provide a starter example for plotting, whereas later examples emphasize deep control and aesthetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "LSj2hBfOp9sG",
    "outputId": "5f54bf74-42e9-4a5a-f792-1e70a0d24a5d"
   },
   "outputs": [],
   "source": [
    "#@title Basic Plot\n",
    "feature = \"sugar\" #@param ['calories', 'carbohydrates', 'fat', 'protein', 'sodium', 'sugar']\n",
    "start_date = \"2022-03-04\" #@param {type:\"date\"}\n",
    "time_interval = \"full time\" #@param [\"one week\", \"full time\"]\n",
    "smoothness = 0.02 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
    "smooth_plot = True #@param {type:\"boolean\"}\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "\n",
    "if time_interval == \"one week\":\n",
    "    day_idxes = [i for i,d in enumerate(dates) if d >= start_date and d <= start_date + timedelta(days=7)]\n",
    "    end_date = start_date + timedelta(days=7)\n",
    "elif time_interval == \"full time\":\n",
    "    day_idxes = [i for i,d in enumerate(dates) if d >= start_date]\n",
    "    end_date = dates[-1]\n",
    "\n",
    "if feature == \"calories\":\n",
    "    calories = dailySummary_df.get(['calories','date'])\n",
    "    concat_cals = []\n",
    "    for i,d in enumerate(dates):\n",
    "        day = d.strftime('%Y-%m-%d')+' 00:00:00'\n",
    "        if i in day_idxes:\n",
    "          calorie = calories[calories['date']==day]\n",
    "          if len(calorie) != 0:\n",
    "              concat_cals += [(day[:10],calorie.iloc[0].calories)]\n",
    "          else:\n",
    "              concat_cals += [(day[:10],None)]\n",
    "    ts = [x[0] for x in concat_cals]\n",
    "\n",
    "    day_arr = [x[1] for x in concat_cals]\n",
    "\n",
    "    sigma = 200 * smoothness\n",
    "\n",
    "    title_fillin = \"Calorie\"\n",
    "\n",
    "  \n",
    "if feature == \"carbohydrates\":\n",
    "    carbohydrates = dailySummary_df.get(['carbohydrates','date'])\n",
    "    concat_carbs = []\n",
    "    for i,d in enumerate(dates):\n",
    "        day = d.strftime('%Y-%m-%d')+' 00:00:00'\n",
    "        if i in day_idxes:\n",
    "          carb = carbohydrates[carbohydrates['date']==day]\n",
    "          if len(carb) != 0:\n",
    "              concat_carbs += [(day[:10],carb.iloc[0].carbohydrates)]\n",
    "          else:\n",
    "              concat_carbs += [(day[:10],None)]\n",
    "    ts = [x[0] for x in concat_carbs]\n",
    "\n",
    "    day_arr = [x[1] for x in concat_carbs]\n",
    "\n",
    "    sigma = 200 * smoothness\n",
    "\n",
    "    title_fillin = \"Carbohydrates (g)\"\n",
    "    \n",
    "if feature == \"fat\":\n",
    "    fats_df = dailySummary_df.get(['fat','date'])\n",
    "    concat_fats = []\n",
    "    for i,d in enumerate(dates):\n",
    "        day = d.strftime('%Y-%m-%d')+' 00:00:00'\n",
    "        if i in day_idxes:\n",
    "          fats = fats_df[fats_df['date']==day]\n",
    "          if len(fats) != 0:\n",
    "              concat_fats += [(day[:10],fats.iloc[0].fat)]\n",
    "          else:\n",
    "              concat_fats += [(day[:10],None)]\n",
    "    ts = [x[0] for x in concat_fats]\n",
    "\n",
    "    day_arr = [x[1] for x in concat_fats]\n",
    "\n",
    "    sigma = 200 * smoothness\n",
    "\n",
    "    title_fillin = \"Fat (g)\"\n",
    "    \n",
    "if feature == \"protein\":\n",
    "    protein_df = dailySummary_df.get(['protein','date'])\n",
    "    concat_proteins = []\n",
    "    for i,d in enumerate(dates):\n",
    "        day = d.strftime('%Y-%m-%d')+' 00:00:00'\n",
    "        if i in day_idxes:\n",
    "          protein = protein_df[protein_df['date']==day]\n",
    "          if len(protein) != 0:\n",
    "              concat_proteins += [(day[:10],protein.iloc[0].protein)]\n",
    "          else:\n",
    "              concat_proteins += [(day[:10],None)]\n",
    "    ts = [x[0] for x in concat_proteins]\n",
    "\n",
    "    day_arr = [x[1] for x in concat_proteins]\n",
    "\n",
    "    sigma = 200 * smoothness\n",
    "\n",
    "    title_fillin = \"Protein (g)\"\n",
    "\n",
    "if feature == \"sugar\":\n",
    "    sugar_df = dailySummary_df.get(['sugar','date'])\n",
    "    concat_sugar = []\n",
    "    for i,d in enumerate(dates):\n",
    "        day = d.strftime('%Y-%m-%d')+' 00:00:00'\n",
    "        if i in day_idxes:\n",
    "          sugar_item = sugar_df[sugar_df['date']==day]\n",
    "          if len(sugar_item) != 0:\n",
    "              concat_sugar += [(day[:10],sugar_item.iloc[0].sugar)]\n",
    "          else:\n",
    "              concat_sugar += [(day[:10],None)]\n",
    "    ts = [x[0] for x in concat_sugar]\n",
    "\n",
    "    day_arr = [x[1] for x in concat_sugar]\n",
    "\n",
    "    sigma = 200 * smoothness\n",
    "\n",
    "    title_fillin = \"Sugar (g)\"\n",
    "\n",
    "if feature == \"sodium\":\n",
    "    sodium_df = dailySummary_df.get(['sodium','date'])\n",
    "    concat_sodium = []\n",
    "    for i,d in enumerate(dates):\n",
    "        day = d.strftime('%Y-%m-%d')+' 00:00:00'\n",
    "        if i in day_idxes:\n",
    "          sodium = sodium_df[sodium_df['date']==day]\n",
    "          if len(sodium) != 0:\n",
    "              concat_sodium += [(day[:10],sodium.iloc[0].sodium)]\n",
    "          else:\n",
    "              concat_sodium += [(day[:10],None)]\n",
    "    ts = [x[0] for x in concat_sodium]\n",
    "\n",
    "    day_arr = [x[1] for x in concat_sodium]\n",
    "\n",
    "    sigma = 200 * smoothness\n",
    "\n",
    "    title_fillin = \"Sodium (g)\"\n",
    "\n",
    "with plt.style.context('ggplot'):\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    if smooth_plot:\n",
    "        def to_numpy(day_arr):\n",
    "            arr_nonone = [x for x in day_arr if x is not None]\n",
    "            mean_val = int(np.mean(arr_nonone))\n",
    "            for i,x in enumerate(day_arr):\n",
    "                if x is None:\n",
    "                    day_arr[i] = mean_val\n",
    "\n",
    "            return np.array(day_arr)\n",
    "\n",
    "        none_idxes = [i for i,x in enumerate(day_arr) if x is None]\n",
    "        day_arr = to_numpy(day_arr)\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        day_arr = list(gaussian_filter(day_arr, sigma=sigma))\n",
    "        for i, x in enumerate(day_arr):\n",
    "            if i in none_idxes:\n",
    "                day_arr[i] = None\n",
    "\n",
    "    plt.plot(ts, day_arr)\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "    plt.title(f\"{title_fillin} from {start_date_str} to {end_date_str}\",\n",
    "              fontsize=20)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.xticks(ts[::int(len(ts)/8)])\n",
    "    plt.ylabel(title_fillin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTLxdx7QbIuR"
   },
   "source": [
    "This plot allows you to quickly scan your data at many different time scales (week and full) and for different kinds of measurements (calories, carbohydrates, fat, protein, sodium, and sugar), which enables easy and fast data exploration.\n",
    "\n",
    "Furthermore, the smoothness parameter makes it easy to look for patterns in long-term trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gr_LPn8b2tN"
   },
   "source": [
    "# 7. Advanced Visualization\n",
    "\n",
    "Now we'll do some more advanced plotting that at times features hardcore matplotlib hacking with the benefit of aesthetic quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KyItag2cSiF"
   },
   "source": [
    "## 4.1 Visualizing participant's Weekly Calorie intake!\n",
    "\n",
    "Whenever our participant is curious and logs into MyFitnessPal App to check their overall Calorie intake summary, the MyFitnessPal app would present their data in the form of a bar chart. It should look something similar to this:\n",
    "\n",
    "<img src=\"https://i.imgur.com/NS9X8DR.jpg\" height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4A_EIgbFcnBf"
   },
   "source": [
    "*Above is a plot from the mobile app itself!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "id": "Bdcn94ataXmt",
    "outputId": "5311c9a2-2791-4183-f422-62def4ad7df1"
   },
   "outputs": [],
   "source": [
    "#@title Set date range for the chart above\n",
    "\n",
    "start = \"2022-05-15\" #@param {type:\"date\"}\n",
    "end = \"2022-05-22\" #@param {type:\"date\"}\n",
    "\n",
    "# Starting date of our chart\n",
    "start_date = date(int(start.split('-')[0]),int(start.split('-')[1]),\n",
    "                  int(start.split('-')[2]))\n",
    "\n",
    "# Ending date of our chart\n",
    "end_date = date(int(end.split('-')[0]),int(end.split('-')[1]),\n",
    "                int(end.split('-')[2]))\n",
    "\n",
    "# A list of all dates between start and end date\n",
    "dates = list(pd.date_range(start_date,end_date,freq='d'))\n",
    "\n",
    "# Creating a dictionary of days with calories\n",
    "calories = {}\n",
    "\n",
    "# Creating a list to store all threshold values (Daily Goals)\n",
    "threshold = []\n",
    "\n",
    "# Saving a list of human readable dates for our reference\n",
    "Dates = []\n",
    "\n",
    "# Appending data for all days between x and y into the calories dictionary\n",
    "for i in dates:\n",
    "    \n",
    "    threshold_data = goals_df[goals_df['date'] == str(i)]\n",
    "    \n",
    "    if len(threshold_data) > 0:\n",
    "        threshold.append(threshold_data.iloc[0].calories)\n",
    "    else:\n",
    "        threshold.append(0)\n",
    "  \n",
    "    Dates.append(str(i))\n",
    "\n",
    "    # xtick values are formatted for matplot lib to recognize the bold and non-bold portions\n",
    "    \n",
    "    calorie_data = dailySummary_df[dailySummary_df['date'] == str(i)]\n",
    "    if len(calorie_data)>0:\n",
    "        calories[\"$\\\\bf{\"+i.strftime(\"%A\")[0]+\"}$\\n\"+\n",
    "           str(i)[8:10]] = calorie_data.iloc[0].calories\n",
    "# Creating DataFrame for our Calorie values and calculating the required metrics\n",
    "calorie_df = pd.DataFrame(calories.items(), columns=['xtick', 'Calorie Value'])\n",
    "calorie_df = calorie_df.assign(Date = Dates)\n",
    "calorie_df = calorie_df.assign(threshold = [float(t) for t in threshold])\n",
    "calorie_df = calorie_df.assign(calorie_under_goal =  \n",
    "                calorie_df.get('threshold') - calorie_df.get('Calorie Value'))\n",
    "calorie_df = calorie_df.set_index('Date')\n",
    "# Creating a matplotlib plot of size 16,8\n",
    "plt1 = plt.figure(figsize=(16,8))\n",
    "ax = plt1.gca()\n",
    "\n",
    "\n",
    "# Setting the title for the plot\n",
    "date_range = (str(start_date.day)+' '+str(start_date.strftime(\"%B\"))+\n",
    "              ' - '+str(end_date.day)+' '+str(end_date.strftime(\"%B\")))\n",
    "plt.title(date_range,fontsize=22)\n",
    "\n",
    "# Plotting the weekly values for calorie intake\n",
    "plt.bar(calorie_df.get('xtick'),calorie_df.get('Calorie Value'), \n",
    "        width=0.65, color =\"#33C77F\")\n",
    "\n",
    "# Plotting the Average Calorie intake\n",
    "plt.bar([\"Avg\"],np.mean(list(calorie_df.get('Calorie Value'))),\n",
    "        width=0.65, color=\"#D8D7DC\")\n",
    "\n",
    "\n",
    "\n",
    "# Adding veritcal grids\n",
    "plt.grid(axis=\"y\", color=\"#D8D7DC\")\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Setting custom yticks of gap 700 calories between each\n",
    "plt.yticks([0,700,1400,2100,2800, 3500])\n",
    "\n",
    "# Removing the spines on top, left and right\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "# Plotting the threshold line\n",
    "plt.axhline(y=np.mean(threshold),linewidth=2.5, color='k')\n",
    "\n",
    "# Changing color of bottom axis and yticks\n",
    "ax.spines['bottom'].set_color('#D8D7DC')\n",
    "ax.tick_params(axis='y', colors='#525252')\n",
    "\n",
    "# Printing the Weekly Statistics\n",
    "plt.figtext(0.1,-0.05,\"─────\"*20,fontsize=16,color=\"#D8D7DC\")\n",
    "plt.figtext(0.1,-0.1,\"Net Calories Under Weekly Goal\", fontsize=16)\n",
    "plt.figtext(0.1,-0.15,\"─────\"*20,fontsize=16,color=\"#D8D7DC\")\n",
    "plt.figtext(0.9,-0.1,str(int(np.sum(calorie_df.get('calorie_under_goal')))),\n",
    "            fontsize=16,color=\"#88878B\")\n",
    "plt.figtext(0.1,-0.2,\"Net Average\", fontsize=16)\n",
    "plt.figtext(0.9,-0.2,str(int(np.mean(calorie_df.get('Calorie Value')))),\n",
    "            fontsize=16,color=\"#88878B\")\n",
    "plt.figtext(0.1,-0.25,\"─────\"*20,fontsize=16,color=\"#D8D7DC\")\n",
    "plt.figtext(0.1,-0.3,\"Goal\", fontsize=16)\n",
    "plt.figtext(0.9,-0.3,str(int(np.mean(calorie_df.get('threshold')))),\n",
    "            fontsize=16,color=\"#2C5391\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oigDYwG4hfzM"
   },
   "source": [
    "*^ Above is a plot we created ourselves!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hz3gqRAMhntc"
   },
   "source": [
    "## 4.2 Visualizing participant's Weekly Workout Reps!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfdtJ5KaibQS"
   },
   "source": [
    "As the API allows us to access a participants fitness data. Next, let's try to find what exercises the participant does the most in a week, this would help them get a clear idea of what muscles are being trained more frequently with the most amount of repetitions. <br><br>\n",
    "Below is a sample chart which we would be modeling our chart on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENYyEkDUid2t"
   },
   "source": [
    "<img src=\"https://i.imgur.com/jQEkl5M.png\" width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5ek0Bd4t1uy"
   },
   "source": [
    "*Above is a plot from the mobile app itself!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "id": "d6H5WhFUoMRC",
    "outputId": "d8e026ac-6569-48c1-fe9c-59eff390b50b"
   },
   "outputs": [],
   "source": [
    "#@title Set date range for the chart below\n",
    "\n",
    "start = \"2022-05-12\" #@param {type:\"date\"}\n",
    "end = \"2022-05-19\" #@param {type:\"date\"}\n",
    "\n",
    "# Starting date of our chart\n",
    "start_date = date(int(start.split('-')[0]),int(start.split('-')[1]),\n",
    "                  int(start.split('-')[2]))\n",
    "\n",
    "# Ending date of our chart\n",
    "end_date = date(int(end.split('-')[0]),int(end.split('-')[1]),\n",
    "                int(end.split('-')[2]))\n",
    "\n",
    "# A list of all dates between start and end date\n",
    "dates = list(pd.date_range(start_date,end_date,freq='d'))\n",
    "\n",
    "# Dictionary to save all the exercises\n",
    "exercises = {}\n",
    "\n",
    "# Going through all the days in the week to count all exercises\n",
    "for d in dates:\n",
    "    day = exercises_strength_df[exercises_strength_df['day']==str(d)]\n",
    "    for i in range(len(day)):\n",
    "        exercise = day.iloc[i]\n",
    "        if exercise['name'] not in exercises:\n",
    "            exercises[exercise['name']] = (exercise['nutrition_information']['sets'] *\n",
    "                                  exercise['nutrition_information']['reps/set'])\n",
    "        else:\n",
    "            exercises[exercise['name']] =+(exercise['nutrition_information']['sets'] *\n",
    "                                  exercise['nutrition_information']['reps/set'])\n",
    "      \n",
    "# Sorting Dictionary in Descending order and storing it in a list\n",
    "exercises = sorted(exercises.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Creating a DataFrame for our exercises and counts\n",
    "exercises_df = pd.DataFrame()\n",
    "exercises_df = exercises_df.assign(Name=[e[0] for e in exercises])\n",
    "exercises_df = exercises_df.assign(Count=[e[1] for e in exercises])\n",
    "\n",
    "# Creating a matplotlib plot of size 16,8\n",
    "plt1 = plt.figure(figsize=(16,8))\n",
    "ax = plt1.gca()\n",
    "\n",
    "\n",
    "# Creating the grids\n",
    "plt.grid(color=\"#a1a1a1\", linestyle='--', linewidth=1, alpha = 0.7)\n",
    "\n",
    "# Setting colors\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "          '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "# Plotting a Bar chart\n",
    "plt.bar(exercises_df.get('Name'),exercises_df.get('Count'), \n",
    "        width=0.5, color=colors)\n",
    "\n",
    "# Rotating xticks\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "# Incresing font size for y ticks\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "# Setting x & y labels\n",
    "plt.ylabel(\"Number of Reps\", size=20)\n",
    "plt.xlabel(\"Workout Activity\", size=20)\n",
    "\n",
    "# Setting plot title\n",
    "plt.title('Number of total reps of each activity in Week', size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V8OxkbUtxxI"
   },
   "source": [
    "*^ Above is a plot we created ourselves!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCiSRYkNtmJU"
   },
   "source": [
    "## 4.3 Participant's Weekly Carbohydrate Intake!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvUWBY4NttDK"
   },
   "source": [
    "Similar to 4.1, whenever our participant is curious and logs into MyFitnessPal App to check their overall Carbohydrates intake summary, the MyFitnessPal app would present their data in the form of a bar chart. It should look something similar to this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGVFVuPJtvc0"
   },
   "source": [
    "<img src=\"https://i.imgur.com/eqQAtFt.jpg\" width='500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ksg25qDWxs5V"
   },
   "source": [
    "*Above is a plot from the mobile app itself!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "id": "5Ao0hzVKtOH_",
    "outputId": "dad73931-b06d-4508-f2ff-a3499b08f614"
   },
   "outputs": [],
   "source": [
    "#@title Set date range for the chart below\n",
    "\n",
    "start = \"2022-05-12\" #@param {type:\"date\"}\n",
    "end = \"2022-05-18\" #@param {type:\"date\"}\n",
    "\n",
    "from matplotlib import lines as mlines\n",
    "\n",
    "# Starting date of our chart\n",
    "start_date = date(int(start.split('-')[0]),int(start.split('-')[1]),\n",
    "                  int(start.split('-')[2]))\n",
    "\n",
    "# Ending date of our chart\n",
    "end_date = date(int(end.split('-')[0]),int(end.split('-')[1]),\n",
    "                int(end.split('-')[2]))\n",
    "\n",
    "# A list of all dates between start and end date\n",
    "dates = list(pd.date_range(start_date,end_date,freq='d'))\n",
    "\n",
    "# Creating a dictionary of days with overall carbohydrates for the day\n",
    "carbs = {}\n",
    "\n",
    "# Storing a list of dates\n",
    "date_list = []\n",
    "\n",
    "# Creating a list to store all carbohydrate threshold values (Daily Goals)\n",
    "carb_threshold = []\n",
    "\n",
    "# Creating a dictionary of days with breakfast carbohydrates for the day\n",
    "brcarbs = {}\n",
    "\n",
    "# Creating a dictionary of days with lunch carbohydrates for the day\n",
    "lunchcarbs = {}\n",
    "\n",
    "# Creating a dictionary of days with dinner carbohydrates for the day\n",
    "dinnercarbs = {}\n",
    "\n",
    "# Creating a dictionary of days with snack carbohydrates for the day\n",
    "sncarbs = {}\n",
    "\n",
    "# Appending data for all days between x and y into the required dictionaries\n",
    "for d in dates:\n",
    "    goal = goals_df[goals_df['date']==str(d)]\n",
    "    if len(goal)>0:\n",
    "        carb_threshold.append(goal.iloc[0].carbohydrates)\n",
    "    else:\n",
    "        carb_threshold.append(0)\n",
    "        \n",
    "    date_list.append(str(d))\n",
    "    \n",
    "    carbs[d.strftime(\"%A\")[0]+\"\\n\"+str(d)[:10].split('-')[-1]] = (0 if\n",
    "    len(dailySummary_df[dailySummary_df['date']==str(d)]) == 0  else dailySummary_df[dailySummary_df['date']==str(d)].iloc[0].carbohydrates)\n",
    "    \n",
    "    brcarbs[d.strftime(\"%A\")[0]+\"\\n\"+str(d)[:10].split('-')[-1]] = (0 if\n",
    "    len(breakfast_df[breakfast_df['day']==str(d)]) == 0  else breakfast_df[breakfast_df['day']==str(d)].iloc[0]['nutrition_information']['carbohydrates'])\n",
    "    \n",
    "    lunchcarbs[d.strftime(\"%A\")[0]+\"\\n\"+str(d)[:10].split('-')[-1]] = (0 if\n",
    "    len(lunch_df[lunch_df['day']==str(d)]) == 0  else lunch_df[lunch_df['day']==str(d)].iloc[0]['nutrition_information']['carbohydrates'])\n",
    "    \n",
    "    dinnercarbs[d.strftime(\"%A\")[0]+\"\\n\"+str(d)[:10].split('-')[-1]] =  (0 if\n",
    "    len(dinner_df[dinner_df['day']==str(d)]) == 0  else dinner_df[dinner_df['day']==str(d)].iloc[0]['nutrition_information']['carbohydrates'])\n",
    "    \n",
    "    sncarbs[d.strftime(\"%A\")[0]+\"\\n\"+str(d)[:10].split('-')[-1]] =  (0 if\n",
    "    len(snacks_df[snacks_df['day']==str(d)]) == 0  else snacks_df[snacks_df['day']==str(d)].iloc[0]['nutrition_information']['carbohydrates'])\n",
    "    \n",
    "    # Calculating the metadata for our legend\n",
    "breakfast_total = sum(brcarbs.values())\n",
    "lunch_total = sum(lunchcarbs.values())\n",
    "dinner_total = sum(dinnercarbs.values())\n",
    "snacks_total = sum(sncarbs.values())\n",
    "carbs_total = list(brcarbs.values())+ list(lunchcarbs.values())+ list(dinnercarbs.values()) + list(sncarbs.values())\n",
    "total_carbs = breakfast_total+lunch_total+dinner_total+snacks_total\n",
    "\n",
    "\n",
    "# Creating a matplotlib plot of size 16,8\n",
    "plt1 = plt.figure(figsize=(16,8))\n",
    "\n",
    "ax = plt1.gca()\n",
    "\n",
    "# Plotting the weekly values for carbohydrates consumed in breakfast\n",
    "plt.bar(brcarbs.keys(),brcarbs.values(), width=0.65, color =\"#1843CE\")\n",
    "\n",
    "# Plotting the weekly values for carbohydrates consumed in lunch\n",
    "plt.bar(lunchcarbs.keys(),lunchcarbs.values(), bottom=list(brcarbs.values()), \n",
    "        width=0.65, color =\"#1B324D\")\n",
    "\n",
    "# Plotting the weekly values for carbohydrates consumed in dinner\n",
    "plt.bar(dinnercarbs.keys(),dinnercarbs.values(), bottom = [l+b for b, l in\n",
    "      zip(brcarbs.values(), lunchcarbs.values())], width=0.65, color=\"#0366ED\")\n",
    "\n",
    "# Plotting the weekly values for carbohydrates consumed in snacks\n",
    "plt.bar(sncarbs.keys(),sncarbs.values(), bottom = [l+b+d for b, l, d in\n",
    "        zip(brcarbs.values(), lunchcarbs.values(),dinnercarbs.values())],\n",
    "        width=0.65, color=\"#0092F0\")\n",
    "\n",
    "# Plotting the Average Calorie intake\n",
    "plt.bar([\"Avg\"],total_carbs/len(carbs),width=0.65, color=\"#D8D7DC\")\n",
    "\n",
    "\n",
    "\n",
    "# Adding veritcal grids\n",
    "plt.grid(axis=\"y\", color=\"#D8D7DC\",lw=2)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Removing the spines on top, left and right\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "# Plotting the threshold line\n",
    "plt.axhline(y=np.max(carbs_total),linewidth=2.5, color='k')\n",
    "\n",
    "#Plotting the legend\n",
    "rect1 = mlines.Line2D([], [], marker=\"s\", markersize=30, linewidth=0,\n",
    "                      color=\"#1843CE\")\n",
    "rect2 = mlines.Line2D([], [], marker=\"s\", markersize=30, linewidth=0,\n",
    "                      color=\"#1B324D\")\n",
    "rect3 = mlines.Line2D([], [], marker=\"s\", markersize=30, linewidth=0,\n",
    "                      color=\"#0366ED\")\n",
    "rect4 = mlines.Line2D([], [], marker=\"s\", markersize=30, linewidth=0,\n",
    "                      color=\"#0092F0\")\n",
    "ax.legend((rect1, rect2,rect3,rect4), (\"Breakfast\"+\"\\n\"+\n",
    "        str(int(breakfast_total / total_carbs *100))+\n",
    "        \"% (\"+str(breakfast_total)+\" g)\", \"Lunch\"+\"\\n\"+\n",
    "        str(int(lunch_total / total_carbs *100))+\"% (\"+str(lunch_total)+\" g)\",\n",
    "         \"Dinner\"+\"\\n\"+str(int(dinner_total / total_carbs *100))+\n",
    "         \"% (\"+str(dinner_total)+\" g)\", \"Snacks\"+\"\\n\"+\n",
    "         str(int(snacks_total / total_carbs *100))+\"% (\"+str(snacks_total)+\" g)\"\n",
    "         ),bbox_to_anchor=(0.5,-0.3), loc=\"center\", frameon=False, ncol=2,\n",
    "          markerscale=1.5, fontsize=16 , labelspacing=3)\n",
    "\n",
    "# Changing color of bottom axis and yticks\n",
    "ax.spines['bottom'].set_color('#D8D7DC')\n",
    "ax.tick_params(axis='y', colors='#525252')\n",
    "\n",
    "# Displaying the Chart Summary\n",
    "plt.figtext(0.125,-0.26,\"─────\"*19,fontsize=16,color=\"#D8D7DC\")\n",
    "plt.figtext(0.125,-0.3,\"Daily Average (g)\", fontsize=16)\n",
    "plt.figtext(0.89,-0.3,str(int(np.mean(list(carbs.values())))),\n",
    "            fontsize=16,color=\"#88878B\")\n",
    "plt.figtext(0.125,-0.34,\"─────\"*19,fontsize=16,color=\"#D8D7DC\")\n",
    "\n",
    "# Adding chart title\n",
    "plt.title('Carbohydrates',fontsize=24,fontweight='bold')\n",
    "\n",
    "\n",
    "# Showing the plot\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmBGPvD4xd_T"
   },
   "source": [
    "*^ Above is a plot we created ourselves!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8zVw2ynx6Z5"
   },
   "source": [
    "# 8. Statistical Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxqLkxfVx9JJ"
   },
   "source": [
    "According to the United States Department of Agriculture (USDA), the recommended daily intake of protein for adult men is 0.8 grams per kilogram of body weight. This is based on a daily energy intake of 2,000 calories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPc09PsYVlte"
   },
   "source": [
    "### Testing Protein Consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uk_Y9rAVlte"
   },
   "source": [
    "For this experiment, let's assume that we are trying to be make sure that the user's consumption of protein should average out to the required protein requirement (population mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDiGGhVNVlte"
   },
   "outputs": [],
   "source": [
    "#@title Set weight (in pounds) for the analysis below\n",
    "weight = 155 #@param {type:\"integer\"}\n",
    "# 1 pound = 0.453592 kg\n",
    "protein_required = weight*0.8*0.453592"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_P-2qrMqVlte"
   },
   "source": [
    "In this section, we will conduct a one-sample t-test to test our protein consumption. To test this hypothesis, we will utilize our data on the user's protein consumption and compare it to the required protein level for their weight. Then, we would then use a t-test to determine whether the difference between the two is statistically significant. If the p-value of the t-test is less than the predetermined alpha level (usually 0.05), we can reject the null hypothesis and conclude that the user's protein consumption is indeed lower than the required protein level. If the p-value is greater than the alpha level, we cannot reject the null hypothesis and must conclude that there is not enough evidence to support the alternative hypothesis. <br>\n",
    "\n",
    "\n",
    "<b>Null hypothesis (H0):</b> The user's protein consumption is equal to or greater than the required protein level.\n",
    "\n",
    "<b>Alternative hypothesis (H1):</b> The user's protein consumption is lower than the required protein level. <br>\n",
    "\n",
    "The one-sample t-test is a statistical test used to determine whether a sample mean is significantly different from a known population mean. The t-test formula for a one-sample t-test is as follows:\n",
    "\n",
    "t = (x̄ - μ) / (s / √n)\n",
    "\n",
    "where:\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li>x̄ is the sample mean</li>\n",
    "<li>μ is the population mean</li>\n",
    "<li>s is the sample standard deviation</li>\n",
    "<li>n is the sample size</li>\n",
    "</ul> <br>\n",
    "The t-test statistic is then used to determine the p-value, which is the probability of obtaining a result as extreme as the one observed, given that the null hypothesis is true. If the p-value is less than the predetermined alpha level (usually 0.05), you can reject the null hypothesis and conclude that there is a statistically significant difference between the sample mean and the population mean. If the p-value is greater than the alpha level, you cannot reject the null hypothesis and must conclude that there is not enough evidence to support the alternative hypothesis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZaZwB8qVltf",
    "outputId": "e3e00210-a9b1-4c7e-9c3e-8110c33c1777"
   },
   "outputs": [],
   "source": [
    "test_result = stats.ttest_1samp(dailySummary_df.get('protein'), popmean=protein_required,alternative='less')\n",
    "\n",
    "print('p-value:',test_result.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QF553ZGXVltf"
   },
   "source": [
    "In this case, as the p-value of the t-test is 1.0, this means that the observed difference between the user's protein consumption and the required protein level is extremely unlikely to have occurred by chance. Based on this result, you cannot reject the null hypothesis and must conclude that there is not enough evidence to support the alternative hypothesis, which is that the user's protein consumption is lower than the required protein level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7EPWmfi0hnO"
   },
   "source": [
    "# 9. Outlier Detection and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHkgd9Fz0rr4"
   },
   "source": [
    "However, even though our P value seems to provide enough statistical significance that our user's protein consumption is not below the USDA's recommendation. However, there might be outliers that are not following this correlation. In this section of our analysis, we will find if there are outliers like that and if they exist, we should find those exact days where protein consumption was lower than recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTt7b69a0ttt"
   },
   "source": [
    "Before finding the individual outlier values, it would be interesting to see the summary of our Protein intake. It will give us a clear idea of what values are typical and which values can be considered atypical based on the data that we recieved from MyFitnessPal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnyMiil-Vltf",
    "outputId": "333ffcfb-7c34-4a45-9d0a-033f2006ae8c"
   },
   "outputs": [],
   "source": [
    "dailySummary_df.get('protein').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwDYabiKVltf"
   },
   "source": [
    "Plotting this data would also make it easier to infer the distribution of our protein intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "g9NJJLbCVltf",
    "outputId": "815db04d-7f2c-436e-8d01-4b561bdee89b"
   },
   "outputs": [],
   "source": [
    "plt.hist(dailySummary_df.get('protein'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qfh3CmRVltf"
   },
   "source": [
    "To identify the outliers in a t-test, you will need to calculate the t-test statistic and compare it to the critical value. Outliers are observations that are significantly different from the rest of the data and can impact the results of the t-test.\n",
    "\n",
    "We will find the 95% confidence interval from our mean using our t-test and use it to find the outlying numbers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb8CsYVCVltj"
   },
   "source": [
    "<img src='https://i.imgur.com/EeJtTL4.png' height=100>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_3Sj8pmVltj",
    "outputId": "156a352c-0e08-4b9e-ad14-8205d79feaa9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import t, sem\n",
    "\n",
    "# Finding ta,df\n",
    "t_a_df = t.ppf(q=.05,df=len(dailySummary_df)-1)\n",
    "\n",
    "# using ta,df to find the lower bound\n",
    "lower_bound = protein_required + (t_a_df*dailySummary_df.get('protein').std())/np.sqrt(len(dailySummary_df.get('protein')))\n",
    "lower_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btkhrG5XVltj"
   },
   "source": [
    "We can use this data to find the days on which our protein intake was less than 50.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2M5fhJ9dVltj",
    "outputId": "66e6a2a3-2255-49cc-f352-3cf5b2f80ee5"
   },
   "outputs": [],
   "source": [
    "res = dailySummary_df.get(['protein','date'])\n",
    "low_protein_days = res[res.protein<=lower_bound].date\n",
    "print(list(low_protein_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqqyKfqjVltj"
   },
   "source": [
    "This is the list of dates where our user's protein intake was lower than the USDA's recommendations"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
