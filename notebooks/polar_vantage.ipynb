{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f97a9b01",
   "metadata": {},
   "source": [
    "# Polar Vantage V2: Guide to data extraction and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8409f",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/xqJvlna.jpeg' height=\"500\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a92f73a",
   "metadata": {},
   "source": [
    "A picture of the Polar Mobile Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb063207",
   "metadata": {},
   "source": [
    "Where do polar bears go to vote? <br>The North Pole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30959560",
   "metadata": {},
   "source": [
    "In this notebook, we would definitely not be visiting the North Pole to watch Polar bears vote. Instead, we will be using the [Polar Vantage V2](https://www.polar.com/en/vantage/v2) which is a smart watch designed for carefully monitoring the most important muscle in your body -- your body. The watch is equipped with advanced wrist-based HR tracking, GPS, ultra-long battery life, running & cycling performance tests, FuelWise, route guidance, sleep tracking, & more. The Vantage V2 can also be utlized to record more than 130 popular sports. It also has an app that you can utilize to view reports on your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f9f27e",
   "metadata": {},
   "source": [
    "This is a comprehensive, clear guide to extract your data from the Polar Flow App using the Wearipedia package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845ce9e",
   "metadata": {},
   "source": [
    "We will be able to extract the following parameters:\n",
    "\n",
    "Parameter Name  | Sampling Frequency \n",
    "-------------------|-----------------\n",
    "Heart Rate |  Every 5 minutes\n",
    "Heart Rate Variability |  Every 5 minutes\n",
    "Breathing Rate |  Every 5 minutes\n",
    "Hypnogram |  For every change detected in sleeping phase \n",
    "Calories |  Per Activity\n",
    "Average and Maximum Heart Rate |  Per Activity\n",
    "Light Sleep Duration | Per Night\n",
    "Deep Sleep Duration | Per Night\n",
    "Interruption Duration | Per Night\n",
    "REM Duration | Per Night\n",
    "<b>Sleep Score</b> | Per Night\n",
    "<b>Sleep Duration</b> | Per Night\n",
    "<b>Sleep Cycles Count</b> | Per Night\n",
    "Sleep Regeneration Score | Per Night\n",
    "Beat to Beat Average | Per Night\n",
    "Heart Rate Variability Average | Per Night\n",
    "Breathing Rate Average | Per Night\n",
    "<b>Heart Rate Average</b> | Per Night"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb73481",
   "metadata": {},
   "source": [
    "** These datatypes are all subsets of sleep and training history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07622639",
   "metadata": {},
   "source": [
    "In this guide, we sequentially cover the following **nine** topics to extract data from Cronometer servers:\n",
    "\n",
    "1. **Setup**<br>\n",
    "2. **Authentication and Authorization**<br>\n",
    "   - Requires only username and password, no OAuth.<br>\n",
    "3. **Data Extraction**<br>\n",
    "  - We get data via wearipedia in a couple lines of code<br>\n",
    "4. **Data Exporting**\n",
    "    - We export all of this data to file formats compatible by R, Excel, and MatLab.\n",
    "5. **Adherence**\n",
    "    - We simulate non-adherence by dynamically removing datapoints from our simulated data.\n",
    "6. **Visualization**\n",
    "    - We create a simple plot to visualize our data.\n",
    "7. **Advanced Visualization**\n",
    "    - 7.1 Visualizing Participants Heart Rate during Sleep! <br>\n",
    "    - 7.2 Visualizing Participants Sleep Breakdown!<br>\n",
    "    - 7.3 Visualizing Weekly Sleep Summary!<br>\n",
    "8. **Statistical Data Analysis** <br>\n",
    "  - 8.1  Analyzing correlation between Sleep Phase and Heart Rate! <br>\n",
    "9. **Outlier Detection and Data Cleaning** <br>\n",
    "  - 9.1 Highlighting Outliers!\n",
    "\n",
    "Disclaimer: this notebook is purely for educational purposes. All of the data currently stored in this notebook is purely *synthetic*, meaning randomly generated according to rules we created. Despite this, the end-to-end data extraction pipeline has been tested on our own data, meaning that if you enter your own email and password on your own Colab instance, you can visualize your own *real* data. That being said, we were unable to thoroughly test the timezone functionality, though, since we only have one account, so beware."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f69277",
   "metadata": {},
   "source": [
    "# 1. Setup\n",
    "\n",
    "## Participant Setup\n",
    "\n",
    "Dear Participant,\n",
    "\n",
    "Once you download the polar flow app, please set it up by following these resources:\n",
    "- Written guide: https://flow.polar.com/start\n",
    "- Video guide: https://www.youtube.com/watch?v=INEeXT8FC9I\n",
    "\n",
    "Make sure that your phone is logged to the polar flow app using the Polar login credentials (email and password) given to you by the data receiver.\n",
    "\n",
    "Best,\n",
    "\n",
    "Wearipedia\n",
    "\n",
    "## Data Receiver Setup\n",
    "\n",
    "Please follow the below steps:\n",
    "\n",
    "1. Create an email address for the participant, for example `foo@email.com`.\n",
    "2. Create a Polar account with the email `foo@email.com` and some random password.\n",
    "3. Keep `foo@email.com` and password stored somewhere safe.\n",
    "4. Request the participant to download the app and instruct them to follow the participant setup letter above.\n",
    "5. Install the `wearipedia` Python package to easily extract data from this device via the Polar API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdcd1749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n",
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install wearipedia\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69965b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wearipedia\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6960f6",
   "metadata": {},
   "source": [
    "# 2. Authentication and Authorization\n",
    "\n",
    "To obtain access to data, authorization is required. Polar uses OAuth2 authentication, so you'll have to create an application following the \"How to get started\" steps here: https://www.polar.com/accesslink-api/?srsltid=AfmBOoq1zjnX5TxZEPRJT5x-JaRTDuzm3sTRokASwvOvkzVQ92edkh6c#how-to-get-started\n",
    "\n",
    "For the client, you can use localhost:8080 as the URL and \"https://test.com\" or any other domain for the web site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74394d52",
   "metadata": {},
   "source": [
    "# 3. Data Extraction\n",
    "\n",
    "Data can be extracted via [wearipedia](https://github.com/Stanford-Health/wearipedia/), our open-source Python package that unifies dozens of complex wearable device APIs into one simple, common interface.\n",
    "\n",
    "First, we'll set a date range and then extract all of the data within that date range. You can select whether you would like synthetic data or not with the checkbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36527391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Enter start and end dates (in the format yyyy-mm-dd)\n",
    "\n",
    "start_date='2025-02-01' #@param {type:\"string\"}\n",
    "end_date='2025-03-01' #@param {type:\"string\"}\n",
    "synthetic = False #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f22756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = wearipedia.get_device(\"polar/vantage\")\n",
    "\n",
    "access_token = \"\" #@param {type: \"string\"}\n",
    "user_id = \"\" #@param {type: \"string\"}\n",
    "# If you don't input the access id or user id, the authentication will walk you through the process interactively.\n",
    "if not synthetic:\n",
    "    device.authenticate({\"access_token\": access_token, \"user_id\": user_id})\n",
    "\n",
    "params = {\"start_date\": start_date, \"end_date\": end_date, 'training_id':'7472390363'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615378f",
   "metadata": {},
   "source": [
    "Let's first extract the sleep data and plot the head of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d45804c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'polar_user': 'https://polaraccesslink.com/v3/users/62710986', 'date': '2025-04-02', 'sleep_start_time': '2025-04-01T22:00:00-07:00', 'sleep_end_time': '2025-04-02T06:00:00-07:00', 'device_id': '', 'continuity': 0.0, 'continuity_class': 0, 'light_sleep': 0, 'deep_sleep': 0, 'rem_sleep': 0, 'unrecognized_sleep_stage': 0, 'sleep_score': 0, 'total_interruption_duration': 0, 'sleep_rating': 0, 'short_interruption_duration': 0, 'long_interruption_duration': 0, 'sleep_goal': 28800, 'hypnogram': {}, 'heart_rate_samples': {}}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polar_user</th>\n",
       "      <th>date</th>\n",
       "      <th>sleep_start_time</th>\n",
       "      <th>sleep_end_time</th>\n",
       "      <th>device_id</th>\n",
       "      <th>continuity</th>\n",
       "      <th>continuity_class</th>\n",
       "      <th>light_sleep</th>\n",
       "      <th>deep_sleep</th>\n",
       "      <th>rem_sleep</th>\n",
       "      <th>unrecognized_sleep_stage</th>\n",
       "      <th>sleep_score</th>\n",
       "      <th>total_interruption_duration</th>\n",
       "      <th>sleep_rating</th>\n",
       "      <th>short_interruption_duration</th>\n",
       "      <th>long_interruption_duration</th>\n",
       "      <th>sleep_goal</th>\n",
       "      <th>hypnogram</th>\n",
       "      <th>heart_rate_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://polaraccesslink.com/v3/users/62710986</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>2025-04-01T22:00:00-07:00</td>\n",
       "      <td>2025-04-02T06:00:00-07:00</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28800</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      polar_user        date  \\\n",
       "0  https://polaraccesslink.com/v3/users/62710986  2025-04-02   \n",
       "\n",
       "            sleep_start_time             sleep_end_time device_id  continuity  \\\n",
       "0  2025-04-01T22:00:00-07:00  2025-04-02T06:00:00-07:00                   0.0   \n",
       "\n",
       "   continuity_class  light_sleep  deep_sleep  rem_sleep  \\\n",
       "0                 0            0           0          0   \n",
       "\n",
       "   unrecognized_sleep_stage  sleep_score  total_interruption_duration  \\\n",
       "0                         0            0                            0   \n",
       "\n",
       "   sleep_rating  short_interruption_duration  long_interruption_duration  \\\n",
       "0             0                            0                           0   \n",
       "\n",
       "   sleep_goal hypnogram heart_rate_samples  \n",
       "0       28800        {}                 {}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep = device.get_data(\"sleep\", params=params)\n",
    "pd.DataFrame(sleep).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698987d",
   "metadata": {},
   "source": [
    "Next, let's plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8bea298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history = device.get_data(\"training_data\", params=params)\n",
    "print(training_history)\n",
    "pd.DataFrame(training_history).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f0e3bb",
   "metadata": {},
   "source": [
    "Lastly, using wearipedia we can also extract this training by id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d2eef79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_by_id = device.get_data(\"training_by_id\", params=params)\n",
    "pd.DataFrame(training_by_id).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd624c37",
   "metadata": {},
   "source": [
    "# 4. Data Exporting\n",
    "\n",
    "In this section, we export all of this data to formats compatible with popular scientific computing software (R, Excel, Google Sheets, Matlab). Specifically, we will first export to JSON, which can be read by R and Matlab. Then, we will export to CSV, which can be consumed by Excel, Google Sheets, and every other popular programming language.\n",
    "\n",
    "## Exporting to JSON (R, Matlab, etc.)\n",
    "\n",
    "Exporting to JSON is fairly simple. We export each datatype separately and also export a complete version that includes all simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6c889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert int64 values to regular Python integers\n",
    "for value in training_history:\n",
    "    for key in value:\n",
    "        if isinstance(value[key], np.int64):\n",
    "            value[key] = int(value[key])\n",
    "\n",
    "json.dump(sleep, open(\"sleep.json\", \"w\"))\n",
    "json.dump(training_history, open(\"training_history.json\", \"w\"))\n",
    "json.dump(training_by_id, open(\"training_by_id.json\", \"w\"))\n",
    "\n",
    "complete = {\n",
    "    \"sleep\": sleep,\n",
    "    \"training_history\": training_history,\n",
    "    \"training_by_id\": training_by_id\n",
    "}\n",
    "\n",
    "json.dump(complete, open(\"complete.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa198c",
   "metadata": {},
   "source": [
    "Feel free to open the file viewer (see left pane) to look at the outputs!\n",
    "\n",
    "## Exporting to CSV and XLSX (Excel, Google Sheets, R, Matlab, etc.)\n",
    "\n",
    "Exporting to CSV/XLSX requires a bit more processing, since they enforce a pretty restrictive schema.\n",
    "\n",
    "We will thus export steps, heart rates, and breath rates all as separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282532b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sleep_df = pd.DataFrame.from_dict(sleep)\n",
    "\n",
    "sleep_df.to_csv('sleep.csv')\n",
    "sleep_df.to_excel('sleep.xlsx')\n",
    "\n",
    "training_history_df = pd.DataFrame.from_dict(training_history)\n",
    "\n",
    "training_history_df.to_csv('training_history.csv', index=False)\n",
    "training_history_df.to_excel('training_history.xlsx', index=False)\n",
    "\n",
    "training_by_id_df = pd.DataFrame.from_dict(training_by_id)\n",
    "\n",
    "training_by_id_df.to_csv('exercises.csv', index=False)\n",
    "training_by_id_df.to_excel('exercises.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32be33f",
   "metadata": {},
   "source": [
    "Again, feel free to look at the output files and download them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e237bf",
   "metadata": {},
   "source": [
    "# 5. Adherence\n",
    "\n",
    "The device simulator already automatically randomly deletes small chunks of the day. In this section, we will simulate non-adherence over longer periods of time from the participant (day-level and week-level).\n",
    "\n",
    "Then, we will detect this non-adherence and give a Pandas DataFrame that concisely describes when the participant has had their device on and off throughout the entirety of the time period, allowing you to calculate how long they've had it on/off etc.\n",
    "\n",
    "We will first delete a certain % of blocks either at the day level or week level, with user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1497a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Non-adherence simulation\n",
    "block_level = \"day\" #@param [\"day\", \"week\"]\n",
    "adherence_percent = 0.89 #@param {type:\"slider\", min:0, max:1, step:0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1edca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if block_level == \"day\":\n",
    "    block_length = 1\n",
    "elif block_level == \"week\":\n",
    "    block_length = 7\n",
    "\n",
    "\n",
    "\n",
    "# This function will randomly remove datapoints from the \n",
    "# data we have recieved from Polar Flow based on the\n",
    "# adherence_percent\n",
    "\n",
    "def AdherenceSimulator(data):\n",
    "\n",
    "    num_blocks = len(data) // block_length\n",
    "    num_blocks_to_keep = int(adherence_percent * num_blocks)\n",
    "    idxes = np.random.choice(np.arange(num_blocks), replace=False, \n",
    "        size=num_blocks_to_keep)\n",
    "\n",
    "    adhered_data = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if i in idxes:\n",
    "            start = i * block_length\n",
    "            end = (i + 1) * block_length\n",
    "            for j in range(i,i+1):\n",
    "                adhered_data.append(data[j])\n",
    "\n",
    "    return adhered_data\n",
    "\n",
    "\n",
    "# Adding adherence for sleep\n",
    "\n",
    "sleep = AdherenceSimulator(sleep)\n",
    "\n",
    "# Adding adherence for exercises\n",
    "\n",
    "training_history = AdherenceSimulator(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17fcd0",
   "metadata": {},
   "source": [
    "And now we have significantly fewer datapoints! This will give us a more realistic situation, where participants may take off their device for days or weeks at a time.\n",
    "\n",
    "Now let's detect non-adherence. We will return a Pandas DataFrame sampled at every day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = pd.DataFrame.from_dict(sleep)\n",
    "training_history_df = pd.DataFrame.from_dict(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87aca1",
   "metadata": {},
   "source": [
    "We can plot this out, and we get adherence at one-day frequency throughout the entirety of the data collection period. For this chart we will plot Energy consumed over the time period from the dailySummary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c2697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=sleep_df.date, y=sleep_df.sleepScore)\n",
    "plt.ylabel('Sleep Score')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5e3aa",
   "metadata": {},
   "source": [
    "# 6. Visualization\n",
    "\n",
    "We've extracted lots of data, but what does it look like?\n",
    "\n",
    "In this section, we will be visualizing our three kinds of data in a simple, customizable plot! This plot is intended to provide a starter example for plotting, whereas later examples emphasize deep control and aesthetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Basic Plot\n",
    "feature = \"Training Recovery Time\" #@param ['Training Calories', 'Training Average Heart Rate','Training Distance','Training Recovery Time']\n",
    "start_date = \"2022-04-21\" #@param {type:\"date\"}\n",
    "time_interval = \"one week\" #@param [\"one week\", \"full time\"]\n",
    "smoothness = 0.02 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
    "smooth_plot = True #@param {type:\"boolean\"}\n",
    "\n",
    "start_date = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "\n",
    "if time_interval == \"one week\":\n",
    "    dates = [start_date + timedelta(days=x) for x in range(((start_date + timedelta(days=6)) - start_date).days + 1)]\n",
    "    day_idxes = [i for i,d in enumerate(dates) if d >= start_date and d <= start_date + timedelta(days=7)]\n",
    "    end_date = start_date + timedelta(days=7)\n",
    "elif time_interval == \"full time\":\n",
    "    dates = [start_date + timedelta(days=x) for x in range((datetime.today() - start_date).days + 1)]\n",
    "    day_idxes = [i for i,d in enumerate(dates) if d >= start_date]\n",
    "    end_date = dates[-1]\n",
    "  \n",
    "if feature == 'Training Calories':\n",
    "    data = training_history_df.get(['startDate','calories']).assign(startDate = training_history_df.get('startDate').apply(lambda x: x[:10]))\n",
    "    concat_data = []\n",
    "    for i,d in enumerate(dates):\n",
    "        day = d.strftime('%Y-%m-%d')\n",
    "        if i in day_idxes:\n",
    "          datapoint = data[data['startDate']==day]\n",
    "          if len(datapoint) != 0:\n",
    "              concat_data += [(day,datapoint.iloc[0].calories)]\n",
    "          else:\n",
    "              concat_data += [(day,None)]\n",
    "    ts = [x[0] for x in concat_data]\n",
    "    day_arr = [x[1] for x in concat_data]\n",
    "    sigma = 200 * smoothness\n",
    "    title_fillin = \"Calories\"\n",
    "\n",
    "if feature == 'Training Average Heart Rate':\n",
    "    data = training_history_df.get(['startDate','hrAvg']).assign(startDate = training_history_df.get('startDate').apply(lambda x: x[:10]))\n",
    "    concat_data = []\n",
    "    for i,d in enumerate(dates):\n",
    "        day = d.strftime('%Y-%m-%d')\n",
    "        if i in day_idxes:\n",
    "          datapoint = data[data['startDate']==day]\n",
    "          if len(datapoint) != 0:\n",
    "              concat_data += [(day,datapoint.iloc[0].hrAvg)]\n",
    "          else:\n",
    "              concat_data += [(day,None)]\n",
    "    ts = [x[0] for x in concat_data]\n",
    "    day_arr = [x[1] for x in concat_data]\n",
    "    sigma = 200 * smoothness\n",
    "    title_fillin = \"Heart Rate (bpm)\"\n",
    "\n",
    "\n",
    "if feature == 'Training Distance':\n",
    "    data = training_history_df.get(['startDate','distance']).assign(startDate = training_history_df.get('startDate').apply(lambda x: x[:10]))\n",
    "    concat_data = []\n",
    "    for i,d in enumerate(dates):\n",
    "        day = d.strftime('%Y-%m-%d')\n",
    "        if i in day_idxes:\n",
    "          datapoint = data[data['startDate']==day]\n",
    "          if len(datapoint) != 0:\n",
    "              concat_data += [(day,datapoint.iloc[0].distance)]\n",
    "          else:\n",
    "              concat_data += [(day,None)]\n",
    "    ts = [x[0] for x in concat_data]\n",
    "    day_arr = [x[1] for x in concat_data]\n",
    "    sigma = 200 * smoothness\n",
    "    title_fillin = \"Training Distance (m)\"\n",
    "\n",
    "if feature == 'Training Recovery Time':\n",
    "    data = training_history_df.get(['startDate','recoveryTime']).assign(startDate = training_history_df.get('startDate').apply(lambda x: x[:10]))\n",
    "    concat_data = []\n",
    "    for i,d in enumerate(dates):\n",
    "        day = d.strftime('%Y-%m-%d')\n",
    "        if i in day_idxes:\n",
    "          datapoint = data[data['startDate']==day]\n",
    "          if len(datapoint) != 0:\n",
    "              concat_data += [(day,datapoint.iloc[0].recoveryTime)]\n",
    "          else:\n",
    "              concat_data += [(day,None)]\n",
    "    ts = [x[0] for x in concat_data]\n",
    "    day_arr = [x[1] for x in concat_data]\n",
    "    sigma = 200 * smoothness\n",
    "    title_fillin = \"Training Recovery Time (s)\"\n",
    "\n",
    "with plt.style.context('ggplot'):\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    if smooth_plot:\n",
    "        def to_numpy(day_arr):\n",
    "            arr_nonone = [x for x in day_arr if x is not None]\n",
    "            mean_val = int(np.mean(arr_nonone))\n",
    "            for i,x in enumerate(day_arr):\n",
    "                if x is None:\n",
    "                    day_arr[i] = mean_val\n",
    "            return np.array(day_arr)\n",
    "\n",
    "        none_idxes = [i for i,x in enumerate(day_arr) if x is None]\n",
    "        day_arr = to_numpy(day_arr)\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        day_arr = list(gaussian_filter(day_arr, sigma=sigma))\n",
    "        for i, x in enumerate(day_arr):\n",
    "            if i in none_idxes:\n",
    "                day_arr[i] = None\n",
    "\n",
    "    plt.plot(ts, day_arr)\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "    plt.title(f\"{title_fillin} from {start_date_str} to {end_date_str}\",\n",
    "              fontsize=20)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.xticks(ts)\n",
    "    plt.ylabel(title_fillin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b825c",
   "metadata": {},
   "source": [
    "This plot allows you to quickly scan your data at many different time scales (week and full) and for different kinds of measurements (heart rate and weight), which enables easy and fast data exploration.\n",
    "\n",
    "Furthermore, the smoothness parameter makes it easy to look for patterns in long-term trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877b852",
   "metadata": {},
   "source": [
    "# 7. Advanced Visualization\n",
    "\n",
    "Now we'll do some more advanced plotting that at times features hardcore matplotlib hacking with the benefit of aesthetic quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffcb2eb",
   "metadata": {},
   "source": [
    "## 7.1 Visualizing Participants Sleep Breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae4700",
   "metadata": {},
   "source": [
    "Polar Vantage V2 has an inbuilt sleep/recovery tracker which allows the participant to track their Sleep into different stages. On the polar flow app, a user can go into their nightly recharge breakdown to check their Hypnograms. The plar flow app should show you the following chart:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83455989",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/HNXVQar.jpg' width='750px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1803b3b",
   "metadata": {},
   "source": [
    "Before getting started with data wrangling, in the box below input the date for which you want to draw the specific plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95c8859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@title Set date for the chart below\n",
    "\n",
    "plot_date = \"2022-05-12\" #@param {type:\"date\"}\n",
    "\n",
    "\n",
    "req_sleep = sleep_df[sleep_df.date==plot_date].iloc[0]\n",
    "start_date = datetime.fromisoformat(req_sleep['sleepStartTime'])\n",
    "hypnodata = req_sleep['sleepWakeStates']\n",
    "sleep_hypnogram_altered = {}\n",
    "sleep_hypnogram_altered_color = {}\n",
    "master_color_key = {'1':'#F8772E','2':'#F8772E','-1':'#45DD9D','-2':'#1559F8','-3':'#5A25A1'}\n",
    "\n",
    "time_dict = {0:0,\n",
    "            1:0,\n",
    "            2:0,\n",
    "            3:0}\n",
    "\n",
    "# Iterating through each key in timestamps except last\n",
    "for i in range(len(hypnodata)-1):\n",
    "\n",
    "    # Getting the current timestamp\n",
    "    key = hypnodata[i]['offsetFromStart']\n",
    "    \n",
    "    key_str = str(start_date.timestamp()+int(key))\n",
    "\n",
    "    # Getting the next timestamp\n",
    "    next_key = hypnodata[i+1]['offsetFromStart']\n",
    "\n",
    "\n",
    "    # Getting the current marking for the hypnogram\n",
    "    value = hypnodata[i]['sleepWakeState']\n",
    "    \n",
    "    milli_seconds = int((int(next_key) - int(key)))\n",
    "    time_dict[value] = time_dict[value] + milli_seconds \n",
    "        \n",
    "    # t_val is the hypnogram value changed to suit our plot\n",
    "    t_val = None\n",
    "\n",
    "    # Value for Light Sleep\n",
    "    if value == 2:\n",
    "        sleep_hypnogram_altered[key_str] = -2\n",
    "        t_val = -2\n",
    "\n",
    "    # Value for Deep Sleep\n",
    "    elif value == 3:\n",
    "        sleep_hypnogram_altered[key_str] = -3\n",
    "        t_val = -3\n",
    "\n",
    "    # Value for REM\n",
    "    elif value == 1:\n",
    "        sleep_hypnogram_altered[key_str] = -1\n",
    "        t_val = -1\n",
    "\n",
    "    # Value for Interruptions\n",
    "    else:\n",
    "        if hypnodata[i]['longInterruption'] == True:\n",
    "            # Longer interruptions\n",
    "            sleep_hypnogram_altered[key_str] = 2\n",
    "            t_val = 2\n",
    "        else:\n",
    "            sleep_hypnogram_altered[key_str] = 1\n",
    "            t_val = 1\n",
    "\n",
    "    # Key to be changed in order to get all the \n",
    "    # keys between the concurrent timestamps\n",
    "    test_key = key\n",
    "\n",
    "    # Setting color for the main timestamp\n",
    "    sleep_hypnogram_altered_color[key_str] = master_color_key[str(t_val)]\n",
    "\n",
    "    # Setting the color and t_val for the test_key\n",
    "    sleep_hypnogram_altered[key_str] = t_val\n",
    "    sleep_hypnogram_altered_color[key_str] = master_color_key[str(t_val)]\n",
    "    for s in range(milli_seconds):\n",
    "        key_str = str(start_date.timestamp()+int(key)+s)\n",
    "         # Setting color for the main timestamp\n",
    "        sleep_hypnogram_altered_color[key_str] = master_color_key[str(t_val)]\n",
    "        # Setting the color and t_val for the test_key\n",
    "        sleep_hypnogram_altered[key_str] = t_val\n",
    "        sleep_hypnogram_altered_color[key_str] = master_color_key[str(t_val)]\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Creating the header figure\n",
    "# Creating the header\n",
    "header = plt.figure(figsize=(14,8), facecolor='white')\n",
    "header_ax = header.gca()\n",
    "header_ax.set_facecolor('white')\n",
    "\n",
    "# Removing x and y ticks for the header\n",
    "plt.xticks([],[])\n",
    "plt.yticks([],[])\n",
    "\n",
    "# Plotting header background image\n",
    "header_img = Image.open(urlopen('https://i.imgur.com/2I4TxYH.png'))\n",
    "plt.imshow(header_img,  interpolation='nearest')\n",
    "\n",
    "# Removing the spines on top, left and right\n",
    "header_ax.spines['top'].set_visible(False)\n",
    "header_ax.spines['right'].set_visible(False)\n",
    "header_ax.spines['left'].set_visible(False)\n",
    "header_ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Function to convert seconds into the time format used in Polar Flow headers\n",
    "def secondsconverter(secs):\n",
    "    if secs//3600 == 0:\n",
    "        return str(int(np.ceil(secs/60)))+'min'\n",
    "    else:\n",
    "        return (str(int(np.floor(secs/3600)))+'h '+\n",
    "            str(int(np.ceil((secs%3600)/60)))+'min')\n",
    "\n",
    "def time_setter(test_date):\n",
    "    if int(test_date.split(':')[0]) > 12:\n",
    "        return test_date + ' PM'\n",
    "    else:\n",
    "        return test_date+' AM'\n",
    "\n",
    "# Displaying header information\n",
    "plt.text(0.765,0.4575,secondsconverter(time_dict[0]),\n",
    "        transform=header.transFigure,fontsize=20,color='white')\n",
    "plt.text(0.56,0.4575,secondsconverter(time_dict[1]),\n",
    "        transform=header.transFigure,fontsize=20,color='white')\n",
    "plt.text(0.3875,0.4575,secondsconverter(time_dict[3]),\n",
    "        transform=header.transFigure,fontsize=20,color='white')\n",
    "plt.text(0.185,0.4575,secondsconverter(time_dict[2]),\n",
    "        transform=header.transFigure,fontsize=20,color='white')\n",
    "\n",
    "# Creating the plot figure\n",
    "plt2 = plt.figure(figsize=(14,8), facecolor='#F1F1F1')\n",
    "ax = plt2.gca()\n",
    "ax.set_facecolor('#F1F1F1')\n",
    "\n",
    "# Removing xticks and yticks\n",
    "plt.xticks([],[])\n",
    "plt.yticks([],[])\n",
    "\n",
    "# Removing the spines on top, left and right\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Creating the sleep cycle text\n",
    "plt.text(0,2.5,'Sleep Cycles: '+str(req_sleep['sleepCycles']), fontsize=20,\n",
    "     color='#B5B5B5')\n",
    "#Setting x-axis to black\n",
    "plt.axhline(y = 0, color = 'black', linestyle = '-',xmin = 0.046, xmax = 0.953)\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.bar(list(sleep_hypnogram_altered.keys()),\n",
    "        list(sleep_hypnogram_altered.values()),width=1,\n",
    "        color=sleep_hypnogram_altered_color.values())\n",
    "\n",
    "# Adding bottom bar to plot in a seprate chart\n",
    "# insert path of the image.\n",
    "b_bar_img = Image.open(urlopen('https://i.imgur.com/RMsObxL.png'))\n",
    "b_bar = plt.figure(figsize = (14,2), facecolor='#F1F1F1')\n",
    "ax2 = b_bar.gca()\n",
    "ax2.set_facecolor('#F1F1F1')\n",
    "\n",
    "# Plotting the image\n",
    "plt.imshow(b_bar_img,  interpolation='nearest')\n",
    "\n",
    "# Removing xticks and yticks\n",
    "plt.xticks([],[])\n",
    "plt.yticks([],[])\n",
    "\n",
    "# Adding text for start and end time\n",
    "start_time =  req_sleep['sleepStartTime'].split('T')[1][:5]\n",
    "plt.text(0.19,0.45,time_setter(start_time),transform=b_bar.transFigure,\n",
    "         color='white',fontsize=20)\n",
    "end_time =  req_sleep['sleepEndTime'].split('T')[1][:5]\n",
    "plt.text(0.735,0.45,time_setter(end_time),transform=b_bar.transFigure,\n",
    "         color='white',fontsize=20)\n",
    "\n",
    "# Adding text for total time\n",
    "total_sleep_secs = sum(list(time_dict.values()))\n",
    "total_time_str = (str(int(np.floor(total_sleep_secs/3600)))+'h '+\n",
    "                  str(int(np.ceil((total_sleep_secs%3600)/60)))+'min')\n",
    "plt.text(0.45,0.45,total_time_str,transform=b_bar.transFigure,\n",
    "         color='white',fontsize=20,fontweight=800)\n",
    "\n",
    "# Removing the spines on top, left and right\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "ax2.spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6abdc0",
   "metadata": {},
   "source": [
    "*^ Above is the plot that we created ourselves!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d839f1",
   "metadata": {},
   "source": [
    "## 7.2 Visualizing Weekly Sleep Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b6c1c",
   "metadata": {},
   "source": [
    "Along with the detailed sleep breakdown, our Polar Vantage also provides information on weekly sleep breakdown. For our next plot, let's recreate the following plot from the Polar Flow app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c93e847",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/jog0iGJ.jpg' width='600px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Set date for the chart below\n",
    "\n",
    "plot_date = \"2022-05-15\" #@param {type:\"date\"}\n",
    "\n",
    "start_date = datetime.strptime(plot_date, '%Y-%m-%d')\n",
    "end_date = start_date + timedelta(6)\n",
    "end_date_str = str(end_date.year)+'-'+str(end_date.month)+'-'+str(end_date.day)\n",
    "weekly_dates_list = []\n",
    "xticks = []\n",
    "for i in pd.date_range(start_date,end_date,freq='d'):\n",
    "    weekly_dates_list.append(str(i)[:10])\n",
    "    test_date = datetime.strptime(str(i)[:10], '%Y-%m-%d')\n",
    "    xticks.append(str(test_date.day)+'        \\n'+\n",
    "                test_date.strftime(\"%A\")[0]+'         ')\n",
    "value_dict = {}\n",
    "goals = []\n",
    "for date in weekly_dates_list:\n",
    "    res = sleep_df[sleep_df['date'] == date]\n",
    "    if len(res)>0:\n",
    "        duration = float(datetime.fromisoformat(res.iloc[0]['sleepEndTime'][:19]).timestamp()) - float(datetime.fromisoformat(res.iloc[0]['sleepStartTime'][:19]).timestamp())\n",
    "        value_dict[date] = duration/3600\n",
    "    else:\n",
    "        value_dict[date] = 0\n",
    "    goals.append(8)\n",
    "# Creating the figure\n",
    "plt3 = plt.figure(figsize=(14,8))\n",
    "ax = plt3.gca()\n",
    "\n",
    "# Adding grid to the plot\n",
    "plt.grid(axis = 'y',color=\"#7F7F7F\", linestyle='-', linewidth=2,alpha=0.8)\n",
    "\n",
    "# Adding the color lines to grid\n",
    "for (x,y) in [(0,2),(4,6),(8,10),(12,14)]:\n",
    "    for i in np.arange(x, y):\n",
    "        plt.axhspan(i, i+1, facecolor='#F2F2F2', alpha=1,\n",
    "                xmin = 0.025, xmax = 0.975)\n",
    "\n",
    "\n",
    "# Plotting line for preferred sleep\n",
    "plt.axhline(np.mean(goals),color='#0C9AE0',lw=3)\n",
    "\n",
    "# Plotting line for average sleep\n",
    "plt.axhline(np.mean(list(value_dict.values())), linestyle='--',\n",
    "            color='#969696',lw=3)\n",
    "\n",
    "# Plotting the values\n",
    "plt.plot(list(value_dict.keys()),list(value_dict.values()), \n",
    "         color='#064C75',lw=3)\n",
    "\n",
    "# Removing margins on left and right of the plot\n",
    "plt.margins(y=0,x=0.1)\n",
    "\n",
    "\n",
    "\n",
    "# Highlighting single data points\n",
    "for x,y in value_dict.items():\n",
    "    plt.plot(x, y, marker=\"o\", markersize=10,\n",
    "    markeredgecolor=\"#2474AA\",markerfacecolor=\"white\", markeredgewidth=2)\n",
    "\n",
    "\n",
    "# Removing the spines on left and right\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "# Modifying our x and y ticks\n",
    "plt.yticks([0,2,4,6,8,10,12,14,16],fontsize=14)\n",
    "plt.xticks(list(value_dict.keys()),xticks,ha='right',fontsize=14)\n",
    "ax.tick_params(axis=u'both', which=u'both',length=0)\n",
    "\n",
    "# Adding header text\n",
    "plt.text(0.09,0.96,'Sleep', transform=plt3.transFigure,\n",
    "         color='#D3D3D4',fontsize=20)\n",
    "plt.text(0.109,0.92,'h', transform=plt3.transFigure,\n",
    "         color='black',fontsize=14)\n",
    "\n",
    "plt.text(0.3,0.96,'Sleep time', transform=plt3.transFigure,\n",
    "         color='black',fontsize=20)\n",
    "plt.text(0.325,0.9,'—', transform=plt3.transFigure,\n",
    "         color='#064C75',fontsize=50)\n",
    "\n",
    "plt.text(0.475,0.96,'Sleep time avg', transform=plt3.transFigure,\n",
    "         color='black',fontsize=20)\n",
    "plt.text(0.525,0.9,'--', transform=plt3.transFigure,\n",
    "         color='#969696',fontsize=50)\n",
    "\n",
    "plt.text(0.69,0.96,'Preferred', transform=plt3.transFigure,\n",
    "         color='black',fontsize=20)\n",
    "plt.text(0.71,0.9,'—', transform=plt3.transFigure,\n",
    "         color='#0C9AE0',fontsize=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7ac02",
   "metadata": {},
   "source": [
    "# 8. Statistical Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4b600",
   "metadata": {},
   "source": [
    "According to a [course](https://www.uh.edu/class/ctr-public-history/tobearfruit/__docs/curriculum/ms/science/conxnbetwrespandhrtrate/lessonplan_conxnbetwrespandhrtrate.pdf) taught at the University of Huston, \"The more the heart beats, the more breathing occurs. As the heart beats faster, it uses more energy and sends more oxygen to the body. If a person is exercising the oxygen is used very quickly in order to provide the muscles with needed energy to move.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f8a02",
   "metadata": {},
   "source": [
    "**Our test hypothesis will be that Heart Rate and Calories Burned are correlated.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a7e802",
   "metadata": {},
   "source": [
    "In this portion of the notebook, we will be testing this exact hypothesis using the data that we fetched from the Polar Vantage 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03746695",
   "metadata": {},
   "source": [
    "First, let's get the required data from the training_history_df dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = training_history_df.get(['calories','hrAvg'])\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c6bd22",
   "metadata": {},
   "source": [
    "Let's create a quick plot on this to see if there is a correlation between these two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea7bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Figure Size in Seaborn\n",
    "sns.set(rc={'figure.figsize':(16,8)})\n",
    "\n",
    "# Setting Seaborn plot style\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "#Plotting our data\n",
    "plot = sns.regplot(data=test_data, x='calories', y=\"hrAvg\")\n",
    "\n",
    "#Renaming x and y labels\n",
    "plot.set_ylabel(\"Breathing Rate\", fontsize = 16)\n",
    "plot.set_xlabel(\"Heart Rate\", fontsize = 16)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab791f",
   "metadata": {},
   "source": [
    "Looking at the graph, we can see a line of regression which hints that Breathing and Heart Rate are directly correlated. However, there seems to be too much variability in the data. In the next line, we will prove this statistically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd752a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "    test_data.get('calories'), test_data.get('hrAvg'))\n",
    "\n",
    "print(f'Slope: {slope:.3g}')\n",
    "print(f'Coefficient of determination: {r_value**2:.3g}')\n",
    "print(f'p-value: {p_value:.3g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74275d51",
   "metadata": {},
   "source": [
    "The p-value for this is 0.875% which is much smaller than the 5% cutoff. This means that there is enough evidence to convincingly conclude that that there is a correlation between Avg Heart Rate and Calories Burned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f69fd",
   "metadata": {},
   "source": [
    "# 9. Outlier Detection and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a531c",
   "metadata": {},
   "source": [
    "However, even though our P value seems to provide enough statistical significance that there is a correlation between Avg Heart Rate and Calories Burned, there might be outliers that are not following this correlation. In this section of our analysis, we will find if there are outliers like that and if they exist, we will visually highlight them in our plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c48324a",
   "metadata": {},
   "source": [
    "Before finding the individual outlier values, it would be interesting to see the summary of our Avg heart Rate and Calories Consumed. It will give us a clear idea of what values are typical and which values can be considered atypical based on the data that we recieved from Cronometer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f32e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d204f9",
   "metadata": {},
   "source": [
    "To locate the outliers we will be using a supervised as well as unsupervised algorithm called the Elliptic Envelope. In statistical studies, Elliptic Envelope created an imaginary elliptical area around a given dataset where values inside that imaginary area is considered to be normal data, and anything else is assumed to be outliers. It assumes that the given Data follows a gaussian distribution.\n",
    "\n",
    "\"The main idea is to define the shape of the data and anomalies are those observations that lie far outside the shape. First a robust estimate of covariance of data is fitted into an ellipse around the central mode. Then, the Mahalanobis distance that is obtained from this estimate is used to define the threshold for determining outliers or anomalies.\" [(S. Shriram and E. Sivasankar ,2019, pp. 221-225)](https://ieeexplore.ieee.org/document/9004325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad6893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes EllipticEnvelope shows slicing based copy warnings\n",
    "# The next line changes a setting that prevents the error from happening\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "#create the model, set the contamination as 0.02\n",
    "EE_model = EllipticEnvelope(contamination = 0.02)\n",
    "\n",
    "#implement the model on the data\n",
    "outliers = EE_model.fit_predict(test_data.get(['calories','hrAvg']))\n",
    "\n",
    "#extract the labels\n",
    "test_data[\"outlier\"] = copy.deepcopy(outliers)\n",
    "\n",
    "#change the labels\n",
    "# We use -1 to mark an outlier and +1 for an inliner\n",
    "test_data[\"outlier\"] = test_data[\"outlier\"].apply(\n",
    "                                    lambda x: str(-1) if x == -1 else str(1))\n",
    "\n",
    "#extract the score\n",
    "test_data[\"EE_scores\"] = EE_model.score_samples(\n",
    "                      test_data.get(['calories','hrAvg']))\n",
    "\n",
    "#print the value counts for inlier and outliers\n",
    "print(test_data[\"outlier\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206a44c7",
   "metadata": {},
   "source": [
    "Below we will replot the test_data dataframe to see how the two new columns were applied to it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee509c",
   "metadata": {},
   "source": [
    "\n",
    "Now that we have labeled the outliers as -1, let's try to see which values of average heart rate and calories are being identified as outliers by our Elliptic Envelope Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df = test_data[test_data.get('outlier')=='-1'].get(\n",
    "    ['calories','hrAvg'])\n",
    "outlier_df_cleaned = outlier_df.drop_duplicates()\n",
    "outlier_df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17972bdd",
   "metadata": {},
   "source": [
    "Sweet, now that we know that there were outliers in our dataset, let's try to visually see which pair of values are being identified as outliers using a plot. Highlighting these outliers in a bright red color will make it super easy for us to identify them in our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d97cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Figure Size in Seaborn\n",
    "sns.set(rc={'figure.figsize':(16,8)})\n",
    "\n",
    "# Setting Seaborn plot style\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "#Plotting our data\n",
    "plot = sns.regplot(x='calories', y='hrAvg', data=test_data.drop(\n",
    "    outlier_df.index))\n",
    "\n",
    "plt.scatter(outlier_df_cleaned.get('calories'),outlier_df_cleaned.get('hrAvg'))\n",
    "plt.scatter(outlier_df_cleaned.get('calories'),outlier_df_cleaned.get('hrAvg'),\n",
    "            facecolors='red',alpha=.35, s=500)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c119051",
   "metadata": {},
   "source": [
    "Thus, the points highlighted in red are ones that seem to not be following the general trend of our dataset. Lastly, let's see what the new p-value is after outlier removal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20133edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "    test_data.drop(outlier_df.index).get('calories'),\n",
    "     test_data.drop(outlier_df.index).get('hrAvg'))\n",
    "\n",
    "print(f'Slope: {slope:.3g}')\n",
    "print(f'Coefficient of determination: {r_value**2:.3g}')\n",
    "print(f'p-value: {p_value:.3g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6835502c",
   "metadata": {},
   "source": [
    "The p-value for this is 0.0115 which is much smaller than the 5% cutoff. This means that there is enough evidence to convincingly conclude that that there is a correlation between Heart Rate and Calories Burned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
